{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_635O_B11_202520-Recommender-System/blob/main/Week3/Saera__Rawas_Recommender_System_Course_Project_GitHub_May_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pZyDezN6cLJ"
      },
      "source": [
        "# Graded Assessment -- AAI 6350 Recommender Systems Course --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrOzAVmq3pWB"
      },
      "source": [
        "# Part 1: Recommendation System Using GCNN [weight: 40\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCoSCUQqjEzp"
      },
      "source": [
        "# Step 1: Data Preparation\n",
        "- Load the Data: Read the Excel file and extract the relevant columns (CustomerID, StockCode, Quantity).\n",
        "- Data Cleaning: Ensure there are no missing values in the relevant columns.\n",
        "- Create Interaction Matrix: Construct an adjacency matrix where rows represent customers and columns represent items. The values in the matrix will be the quantities purchased."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lc0BmAXOjBAH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(\"/content/Rec_sys_data.xlsx\")\n",
        "\n",
        "# Create a pivot table to form the interaction matrix\n",
        "interaction_matrix = data.pivot_table(index='CustomerID', columns='StockCode', values='Quantity', fill_value=0)\n",
        "\n",
        "# Convert to a NumPy array for further processing\n",
        "interaction_matrix = interaction_matrix.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmkY6QpXjRE8"
      },
      "source": [
        "# Step 2: Graph Construction [25 points]\n",
        "- Graph Representation: Each customer and item will be a node in the graph. An edge exists between a customer and an item if the customer has purchased that item.\n",
        "- Adjacency Matrix: Create an adjacency matrix where the rows represent customers and the columns represent items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AodAQLK-0vff",
        "outputId": "9ed76d07-e45d-41f9-80b7-c3099bf3b99c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the Adjacency Matrix (Customers x Items): (3647, 3538)\n",
            "\n",
            "First 5 rows of the Adjacency Matrix:\n",
            "[[1 1 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Adjacency DataFrame (first 5 rows and columns):\n",
            "       84029E  71053  21730  84406B  22752\n",
            "17850       1      1      1       1      1\n",
            "13047       0      0      0       0      0\n",
            "12583       0      0      0       0      0\n",
            "13748       0      0      0       0      0\n",
            "15100       0      0      0       0      0\n"
          ]
        }
      ],
      "source": [
        "# Get unique customers and items (StockCode)\n",
        "customers = data['CustomerID'].unique()\n",
        "items = data['StockCode'].unique()\n",
        "\n",
        "# Create mappings from customer/item IDs to matrix indices\n",
        "customer_to_index = {customer: i for i, customer in enumerate(customers)}\n",
        "item_to_index = {item: j for j, item in enumerate(items)}\n",
        "\n",
        "# Initialize the adjacency matrix with zeros\n",
        "num_customers = len(customers)\n",
        "num_items = len(items)\n",
        "adjacency_matrix = np.zeros((num_customers, num_items), dtype=int)\n",
        "\n",
        "# Populate the adjacency matrix: 1 if a customer purchased an item, 0 otherwise\n",
        "for index, row in data.iterrows():\n",
        "    customer_id = row['CustomerID']\n",
        "    item_id = row['StockCode']\n",
        "    if customer_id in customer_to_index and item_id in item_to_index:\n",
        "        customer_index = customer_to_index[customer_id]\n",
        "        item_index = item_to_index[item_id]\n",
        "        adjacency_matrix[customer_index, item_index] = 1\n",
        "\n",
        "# Print the shape of the adjacency matrix and a few rows to verify\n",
        "print(\"Shape of the Adjacency Matrix (Customers x Items):\", adjacency_matrix.shape)\n",
        "print(\"\\nFirst 5 rows of the Adjacency Matrix:\")\n",
        "print(adjacency_matrix[:5])\n",
        "\n",
        "# Create a DataFrame for better visualization if needed\n",
        "adjacency_df = pd.DataFrame(adjacency_matrix, index=customers, columns=items)\n",
        "print(\"\\nAdjacency DataFrame (first 5 rows and columns):\")\n",
        "print(adjacency_df.iloc[:5, :5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM779u1Mjf-0"
      },
      "source": [
        "# Step 3: Model Definition (GCNN) [35 points]\n",
        "- Define the GCNN Architecture: Use a library like PyTorch Geometric or TensorFlow with Keras to define the GCNN model.\n",
        "- The model will consist of graph convolutional layers that learn representations for both customers and items.\n",
        "- Prepare Data for Training: Convert the adjacency matrix and features into a format suitable for the GCNN."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4gReGdbmsnL",
        "outputId": "48811c0a-2d24-4453-e4d4-9fbc203e74e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt26cu124\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-frdon72v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-frdon72v\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 433b3c96e2494923124caa0791a966ce25d14257\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (4.67.1)\n",
            "Collecting xxhash (from torch-geometric==2.7.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2025.4.26)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1206610 sha256=56f198bf560ddae89ce0734541cad9db79edb1d0ff95e0aaeabfcadc5e4bd709\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h7l1dcji/wheels/93/bb/85/bfec4ee59b2563f74ec87cc2c91c6a4d3e40d3dcdec8ee5afe\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: xxhash, torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Convert adjacency matrix to edge list (source and target)\n",
        "edges = []\n",
        "\n",
        "for customer_index in range(num_customers):\n",
        "    for item_index in range(num_items):\n",
        "        if adjacency_matrix[customer_index, item_index] == 1:\n",
        "            edges.append([customer_index, num_customers + item_index])  # Customer nodes: 0 to num_customers-1, Item nodes: num_customers to num_customers+num_items-1\n",
        "\n",
        "edges = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "\n",
        "# If you don't have additional features, you can just use ones as dummy features\n",
        "customer_features = torch.ones(num_customers, 1)  # Example: all customers having the same feature\n",
        "item_features = torch.ones(num_items, 1)  # Example: all items having the same feature\n",
        "node_features = torch.cat([customer_features, item_features], dim=0)  # Concatenate customer and item features\n",
        "\n",
        "# Create the Data object (PyTorch Geometric format)\n",
        "data = Data(x=node_features, edge_index=edges)\n"
      ],
      "metadata": {
        "id": "NVpPG-01h9rO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "class GCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNN, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_channels, out_channels)\n",
        "        self.fc = nn.Linear(out_channels, 1)  # Output a single prediction (e.g., purchase likelihood)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply first convolutional layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Apply second convolutional layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Apply a fully connected layer (optional)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "HqYUMDMth_pL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "# Set model, optimizer, and loss function\n",
        "model = GCNN(in_channels=1, hidden_channels=64, out_channels=32)  # Example channel sizes\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary classification (purchase/no-purchase)\n",
        "\n",
        "# Example training loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    out = model(data)\n",
        "\n",
        "    # Get edge indices\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # Create target tensor based on edges\n",
        "    target = torch.tensor(adjacency_matrix[edge_index[0], edge_index[1] - num_customers], dtype=torch.float)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = criterion(out[edge_index[0]].view(-1), target.view(-1)) # Select predictions for edges only\n",
        "\n",
        "    # Backpropagate\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYNMpCvKiBxB",
        "outputId": "2f80248b-57de-4a9d-a0f4-ddf1c14b99c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6499851942062378\n",
            "Epoch 10, Loss: 0.05860096588730812\n",
            "Epoch 20, Loss: 0.0002991936053149402\n",
            "Epoch 30, Loss: 9.804309229366481e-06\n",
            "Epoch 40, Loss: 2.0146237602602923e-06\n",
            "Epoch 50, Loss: 1.0453805998622556e-06\n",
            "Epoch 60, Loss: 8.070801982285047e-07\n",
            "Epoch 70, Loss: 7.305415579139662e-07\n",
            "Epoch 80, Loss: 7.032174380583456e-07\n",
            "Epoch 90, Loss: 6.928557354513032e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(data)\n",
        "    predictions = torch.sigmoid(predictions).view(-1)  # Convert logits to probabilities\n"
      ],
      "metadata": {
        "id": "VrzjAbUxiDgc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG6dBRgXj4Q4"
      },
      "source": [
        "# Step 4: Training the Model [40 points]\n",
        "\n",
        "- Loss Function: Use a suitable loss function, such as Mean Squared Error (MSE) as we are working with continuous interaction scores.\n",
        "- Optimizer: Choose an optimizer like Adam or SGD.\n",
        "- Training Loop: Implement the training loop to update the model weights based on the loss. In each epoch, calculate the predictions using the model, compute the loss between predicted and actual values, and perform backpropagation to update the model's weights.\n",
        "- Also compute the validation loss to evaluate the model's performance on unseen data, and use early stopping to halt training when the validation loss stops improving, preventing overfitting."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# 1. Prepare the data with proper train/val split\n",
        "# Convert edge indices and features to numpy first\n",
        "edge_index_np = data.edge_index.numpy().T\n",
        "edge_labels = torch.tensor(adjacency_matrix[edge_index_np[:, 0], edge_index_np[:, 1] - num_customers], dtype=torch.float)\n",
        "\n",
        "# Split edges into train and validation sets\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(edge_index_np.shape[0]),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_edge_index = torch.tensor(edge_index_np[train_idx], dtype=torch.long).t().contiguous()\n",
        "val_edge_index = torch.tensor(edge_index_np[val_idx], dtype=torch.long).t().contiguous()\n",
        "\n",
        "train_labels = edge_labels[train_idx]\n",
        "val_labels = edge_labels[val_idx]\n",
        "\n",
        "# 2. Modify the model for regression (since you mentioned continuous scores)\n",
        "class GCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNN, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_channels, out_channels)\n",
        "        self.fc = nn.Linear(out_channels, 1)\n",
        "\n",
        "    def forward(self, data, edge_index=None):\n",
        "        x, full_edge_index = data.x, data.edge_index\n",
        "        edge_index = full_edge_index if edge_index is None else edge_index\n",
        "\n",
        "        x = self.conv1(x, full_edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, full_edge_index)\n",
        "        x = torch.relu(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# 3. Initialize model, optimizer, and loss\n",
        "model = GCNN(in_channels=1, hidden_channels=64, out_channels=32)\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()  # For continuous interaction scores\n",
        "\n",
        "# 4. Training loop with early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass on training edges\n",
        "preds = model(data, train_edge_index)\n",
        "\n",
        "# Get predictions only for the relevant edges\n",
        "train_preds = preds[train_edge_index[0]].view(-1) # Select predictions for edges only\n",
        "\n",
        "# Calculate the loss using only the predictions for the edges in the training dataset\n",
        "train_loss = criterion(train_preds, train_labels)\n",
        "# Backpropagation\n",
        "train_loss.backward()\n",
        "optimizer.step()\n",
        "# Validation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_preds = model(data, val_edge_index) # Get predictions only for validation edges\n",
        "    val_loss = criterion(val_preds[val_edge_index[0]].view(-1), val_labels) # Select predictions for edges only and compare with labels\n",
        "# Early stopping check\n",
        "if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "else:\n",
        "        patience_counter += 1\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "# 1. Prepare the data with proper train/val split\n",
        "# Convert edge indices and features to numpy first\n",
        "edge_index_np = data.edge_index.numpy().T\n",
        "edge_labels = torch.tensor(adjacency_matrix[edge_index_np[:, 0], edge_index_np[:, 1] - num_customers], dtype=torch.float)\n",
        "\n",
        "# Split edges into train and validation sets\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(edge_index_np.shape[0]),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_edge_index = torch.tensor(edge_index_np[train_idx], dtype=torch.long).t().contiguous()\n",
        "val_edge_index = torch.tensor(edge_index_np[val_idx], dtype=torch.long).t().contiguous()\n",
        "\n",
        "train_labels = edge_labels[train_idx]\n",
        "val_labels = edge_labels[val_idx]\n",
        "\n",
        "# 2. Modify the model for regression (since you mentioned continuous scores)\n",
        "class GCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNN, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_channels, out_channels)\n",
        "        self.fc = nn.Linear(out_channels, 1)\n",
        "\n",
        "    def forward(self, data, edge_index=None):\n",
        "        x, full_edge_index = data.x, data.edge_index\n",
        "        edge_index = full_edge_index if edge_index is None else edge_index\n",
        "\n",
        "        x = self.conv1(x, full_edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, full_edge_index)\n",
        "        x = torch.relu(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# 3. Initialize model, optimizer, and loss\n",
        "model = GCNN(in_channels=1, hidden_channels=64, out_channels=32)\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()  # For continuous interaction scores\n",
        "\n",
        "# 4. Training loop with early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass on training edges\n",
        "    preds = model(data, train_edge_index)\n",
        "\n",
        "    # Get predictions only for the relevant edges\n",
        "    train_preds = preds[train_edge_index[0]].view(-1) # Select predictions for edges only\n",
        "\n",
        "    # Calculate the loss using only the predictions for the edges in the training dataset\n",
        "    train_loss = criterion(train_preds, train_labels)\n",
        "    # Backpropagation\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_preds = model(data, val_edge_index) # Get predictions only for validation edges\n",
        "        val_loss = criterion(val_preds[val_edge_index[0]].view(-1), val_labels) # Select predictions for edges only and compare with labels\n",
        "    # Early stopping check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f'Epoch {epoch}: Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdIg9--r2j62",
        "outputId": "86d1b7ff-a0b5-48ce-b1c3-1e058fb173f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss: 0.9092, Val Loss: 0.6144\n",
            "Epoch 5: Train Loss: 0.0398, Val Loss: 0.0005\n",
            "Early stopping at epoch 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qGm-oBQ3w-y"
      },
      "source": [
        "# Part 2: Recommendation System Evaluation and Comparison Using GCNN and NeuMF Models [weight: 30\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Be3vugeLBvo"
      },
      "source": [
        "# Step 1: Evaluation [40 points]\n",
        "\n",
        "To calculate the average precision, recall, and F1 score for all customers, follow these steps:\n",
        "\n",
        "- Obtain Model Predictions: Use the trained model to predict interaction scores for all customer-item pairs in the validation set.\n",
        "\n",
        "- Rank Items by Predicted Scores: For each customer, rank items based on the predicted interaction scores in descending order.\n",
        "\n",
        "- Define Relevant Items: Set a threshold to determine which items are considered relevant (e.g., based on the top-k predictions or actual interactions greater than zero).\n",
        "\n",
        "- Calculate Precision, Recall, and F1 Score for Each Customer: For each customer, calculate precision, recall, and F1 score using the relevant predicted and actual items.\n",
        "\n",
        "- Compute Average Precision, Recall, and F1 Score: Calculate the mean of precision, recall, and F1 scores across all customers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(data).view(-1)  # Get raw scores\n"
      ],
      "metadata": {
        "id": "o67OMkQCpHka"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Dictionaries to store predictions and ground truth per customer\n",
        "predictions_per_customer = defaultdict(list)\n",
        "actuals_per_customer = defaultdict(set)\n",
        "\n",
        "# Use val_edge_index instead of val_edges\n",
        "for i in range(val_edge_index.shape[1]):\n",
        "    customer_idx = val_edge_index[0, i].item()\n",
        "    item_idx = val_edge_index[1, i].item() - num_customers  # Convert to item index\n",
        "\n",
        "    score = output[val_edge_index[0, i]].item()  # Predicted score\n",
        "    actual = adjacency_matrix[customer_idx, item_idx]\n",
        "\n",
        "    predictions_per_customer[customer_idx].append((item_idx, score))\n",
        "    if actual > 0:\n",
        "        actuals_per_customer[customer_idx].add(item_idx)\n"
      ],
      "metadata": {
        "id": "JjyaxFeSpK8p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def precision_recall_f1(y_true, y_pred):\n",
        "    if not y_pred:\n",
        "        return 0.0, 0.0, 0.0\n",
        "    y_true_bin = [1 if item in y_true else 0 for item in y_pred]\n",
        "    y_pred_bin = [1] * len(y_pred)\n",
        "\n",
        "    tp = sum(y_true_bin)\n",
        "    precision = tp / len(y_pred)\n",
        "    recall = tp / len(y_true) if y_true else 0.0\n",
        "    f1 = (2 * precision * recall) / (precision + recall + 1e-8)  # Avoid divide by zero\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Store all scores\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "\n",
        "k = 10  # Top-k items to recommend\n",
        "\n",
        "for customer, predictions in predictions_per_customer.items():\n",
        "    predictions_sorted = sorted(predictions, key=lambda x: x[1], reverse=True)\n",
        "    top_k_items = [item for item, score in predictions_sorted[:k]]\n",
        "    actual_items = actuals_per_customer[customer]\n",
        "\n",
        "    p, r, f = precision_recall_f1(actual_items, top_k_items)\n",
        "    precision_list.append(p)\n",
        "    recall_list.append(r)\n",
        "    f1_list.append(f)\n",
        "\n",
        "# Compute averages\n",
        "avg_precision = np.mean(precision_list)\n",
        "avg_recall = np.mean(recall_list)\n",
        "avg_f1 = np.mean(f1_list)\n",
        "\n",
        "print(f\"Average Precision@{k}: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall@{k}: {avg_recall:.4f}\")\n",
        "print(f\"Average F1 Score@{k}: {avg_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jElbrjRgpOKB",
        "outputId": "125c980e-f9cb-46a6-9280-ba1879ff0e09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision@10: 1.0000\n",
            "Average Recall@10: 0.8408\n",
            "Average F1 Score@10: 0.8872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "class GCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNN, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_channels, out_channels)\n",
        "        self.fc = nn.Linear(out_channels, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = torch.relu(self.conv1(x, edge_index))\n",
        "        x = torch.relu(self.conv2(x, edge_index))\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "5vw9TrWnqiuh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_gcnn(model, data, adjacency_matrix, num_customers, num_items, top_k=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        scores = model(data).view(-1)\n",
        "\n",
        "    item_scores = scores[num_customers:]  # Item nodes only\n",
        "\n",
        "    precision_list, recall_list, f1_list = [], [], []\n",
        "\n",
        "    for cust_idx in range(num_customers):\n",
        "        actual_indices = np.where(adjacency_matrix[cust_idx] > 0)[0]\n",
        "        if len(actual_indices) == 0:\n",
        "            continue  # Skip customers with no purchases\n",
        "\n",
        "        predicted_scores = item_scores  # Same for all customers\n",
        "        top_k_items = torch.topk(predicted_scores, k=top_k).indices.tolist()\n",
        "\n",
        "        actual_set = set(actual_indices)\n",
        "        pred_set = set(top_k_items)\n",
        "\n",
        "        tp = len(actual_set & pred_set)\n",
        "        precision = tp / top_k\n",
        "        recall = tp / len(actual_set)\n",
        "        f1 = (2 * precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "    return np.mean(precision_list), np.mean(recall_list), np.mean(f1_list)\n"
      ],
      "metadata": {
        "id": "SWXthip1qlT-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuMF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim=32):\n",
        "        super(NeuMF, self).__init__()\n",
        "        self.user_embed = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embed = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * embedding_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, user_indices, item_indices):\n",
        "        u = self.user_embed(user_indices)\n",
        "        v = self.item_embed(item_indices)\n",
        "        x = torch.cat([u, v], dim=-1)\n",
        "        return self.mlp(x).squeeze()\n"
      ],
      "metadata": {
        "id": "WeJjRy2KqoOz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_neumf(model, adjacency_matrix, top_k=10):\n",
        "    model.eval()\n",
        "    precision_list, recall_list, f1_list = [], [], []\n",
        "\n",
        "    num_users, num_items = adjacency_matrix.shape\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for user in range(num_users):\n",
        "            actual_items = np.where(adjacency_matrix[user] > 0)[0]\n",
        "            if len(actual_items) == 0:\n",
        "                continue\n",
        "\n",
        "            item_indices = torch.arange(num_items)\n",
        "            user_tensor = torch.full((num_items,), user, dtype=torch.long)\n",
        "\n",
        "            scores = model(user_tensor, item_indices)\n",
        "            top_items = torch.topk(scores, k=top_k).indices.tolist()\n",
        "\n",
        "            actual_set = set(actual_items)\n",
        "            pred_set = set(top_items)\n",
        "\n",
        "            tp = len(actual_set & pred_set)\n",
        "            precision = tp / top_k\n",
        "            recall = tp / len(actual_set)\n",
        "            f1 = (2 * precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "            precision_list.append(precision)\n",
        "            recall_list.append(recall)\n",
        "            f1_list.append(f1)\n",
        "\n",
        "    return np.mean(precision_list), np.mean(recall_list), np.mean(f1_list)\n"
      ],
      "metadata": {
        "id": "2YZXxMTrqqJk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcnn_model = GCNN(in_channels=1, hidden_channels=64, out_channels=32) # Example channel sizes\n",
        "gcnn_data = data\n",
        "\n",
        "# Example usage after training both models:\n",
        "gcnn_p, gcnn_r, gcnn_f1 = evaluate_gcnn(gcnn_model, gcnn_data, adjacency_matrix, num_customers, num_items)\n",
        "print(f\"GCNN -> Precision@10: {gcnn_p:.4f}, Recall@10: {gcnn_r:.4f}, F1: {gcnn_f1:.4f}\")\n",
        "\n",
        "# Make sure num_customers and num_items are defined\n",
        "neumf_model = NeuMF(num_users=num_customers, num_items=num_items)\n",
        "\n",
        "neumf_p, neumf_r, neumf_f1 = evaluate_neumf(neumf_model, adjacency_matrix)\n",
        "print(f\"NeuMF -> Precision@10: {neumf_p:.4f}, Recall@10: {neumf_r:.4f}, F1: {neumf_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE6PPG1mqr9P",
        "outputId": "55f6ffe8-24da-4e8a-a3df-57af106b5eeb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCNN -> Precision@10: 0.1580, Recall@10: 0.0420, F1: 0.0528\n",
            "NeuMF -> Precision@10: 0.0155, Recall@10: 0.0036, F1: 0.0046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Metrics Comparison\n",
        "\n",
        "Metric\t          GCNN\t       NeuMF\n",
        "\n",
        "Precision@10\t    0.1580\t    0.0155\n",
        "\n",
        "Recall@10\t        0.0420\t    0.0036\n",
        "\n",
        "F1 Score\t        0.0528\t    0.0046\n",
        "\n",
        "\n",
        "Analysis\n",
        "\n",
        "✅ Precision@10\n",
        "GCNN achieves a precision of 15.8%, which is 10x higher than NeuMF’s 1.55%.\n",
        "\n",
        "This means that among the top 10 recommended items, GCNN returns significantly more relevant items than NeuMF.\n",
        "\n",
        "Implication: GCNN is better at ranking relevant items higher, which is critical in top-K recommendation tasks.\n",
        "\n",
        "✅ Recall@10\n",
        "GCNN recall is 4.20%, compared to NeuMF’s 0.36%, indicating it captures more of the relevant items from the full ground truth.\n",
        "\n",
        "While both recall values are relatively low (typical in sparse recommendation settings), GCNN still retrieves more useful recommendations.\n",
        "\n",
        "Implication: GCNN explores and captures a broader set of relevant items than NeuMF.\n",
        "\n",
        "✅ F1 Score\n",
        "F1 score balances precision and recall; GCNN's score of 0.0528 is far superior to NeuMF’s 0.0046.\n",
        "\n",
        "This suggests that GCNN maintains a better trade-off between precision and recall.\n",
        "\n",
        "Why GCNN Outperforms NeuMF\n",
        "Graph Structural Awareness:\n",
        "\n",
        "GCNN leverages graph connectivity (e.g., user-item interaction graphs), capturing higher-order relationships, such as indirect connections and user similarity patterns.\n",
        "\n",
        "NeuMF, being a standard feedforward architecture, lacks this ability to model rich collaborative signals.\n",
        "\n",
        "Message Passing:\n",
        "\n",
        "GCNN applies message passing and neighborhood aggregation, allowing the model to incorporate contextual information from nearby nodes (e.g., similar users or items), leading to more accurate recommendations.\n",
        "\n",
        "Expressiveness:\n",
        "\n",
        "While NeuMF can model non-linear interactions, it still works on latent factors alone. GCNN enriches these latent representations by integrating topological information, enhancing its expressiveness.\n",
        "\n",
        "Conclusion\n",
        "The GCNN model is clearly superior to the NeuMF model across all key metrics. The strength of GCNN lies in its ability to incorporate graph-based relationships, which are crucial in recommendation systems where user-item interactions form sparse and complex networks. Unless NeuMF is significantly enhanced or tailored with more sophisticated architectures, GCNN should be the preferred model in this context."
      ],
      "metadata": {
        "id": "HKQiZ-JcSI0B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYvJq4c4iz2l"
      },
      "source": [
        "# Step 2: Generating Recommendations and Evaluating for a Specific Customer [40 points]\n",
        "\n",
        "1- Mapping Customer IDs to Indices.\n",
        "\n",
        "2- Get Predicted Scores for the Customer.\n",
        "\n",
        "3- Rank Items by Predicted Scores.\n",
        "\n",
        "4- Map Recommended Items to Stock Codes.\n",
        "\n",
        "5- Compare Recommendations with Actual Interactions.\n",
        "\n",
        "6- Calculate Precision, Recall, and F1 Score."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_to_index = {customer: i for i, customer in enumerate(customers)}\n",
        "index_to_customer = {i: customer for i, customer in enumerate(customers)}\n",
        "item_to_index = {item: j for j, item in enumerate(items)}\n",
        "index_to_item = {j: item for j, item in enumerate(items)}\n"
      ],
      "metadata": {
        "id": "Axv8D-hppjnG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_id = customers[0]  # Or any ID of interest\n",
        "customer_idx = customer_to_index[customer_id]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    scores = model(data).view(-1)\n",
        "\n",
        "# Get predicted scores for all item nodes (offset by num_customers)\n",
        "item_scores = scores[num_customers:]  # Only item nodes\n"
      ],
      "metadata": {
        "id": "FbOEhPfMpn4W"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort items by descending predicted scores\n",
        "top_k = 10\n",
        "ranked_items = torch.topk(item_scores, k=top_k).indices.tolist()\n"
      ],
      "metadata": {
        "id": "50U56fjgpntM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_stock_codes = [index_to_item[i] for i in ranked_items]\n",
        "print(f\"Top-{top_k} recommended items for customer {customer_id}:\")\n",
        "print(recommended_stock_codes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3GCU8IZpv0T",
        "outputId": "8a984d30-eb29-4809-d513-f5e4f126b1b2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-10 recommended items for customer 17850:\n",
            "[22423, '85123A', 47566, 21212, 22720, 84879, '85099B', 22960, 23298, 22457]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get actual items purchased by the customer\n",
        "actual_purchased_item_indices = np.where(adjacency_matrix[customer_idx] > 0)[0]\n",
        "actual_stock_codes = [index_to_item[i] for i in actual_purchased_item_indices]\n",
        "\n",
        "print(f\"\\nActual purchased items by customer {customer_id}:\")\n",
        "print(actual_stock_codes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5nH8Z6cpydW",
        "outputId": "cac7d02b-a7a9-4a42-e5ed-f452d7964e1b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Actual purchased items by customer 17850:\n",
            "['84029E', 71053, 21730, '84406B', 22752, '85123A', '84029G', 22633, 22632, 20679, 21068, 21871, 82483, 21071, 82486, 37370, '82494L', 82482, '15056BL', 22411, 22803]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_f1_set(y_true, y_pred):\n",
        "    y_true_set = set(y_true)\n",
        "    y_pred_set = set(y_pred)\n",
        "    tp = len(y_true_set & y_pred_set)\n",
        "\n",
        "    precision = tp / len(y_pred) if y_pred else 0.0\n",
        "    recall = tp / len(y_true) if y_true else 0.0\n",
        "    f1 = (2 * precision * recall) / (precision + recall + 1e-8)\n",
        "    return precision, recall, f1\n",
        "\n",
        "precision, recall, f1 = precision_recall_f1_set(actual_stock_codes, recommended_stock_codes)\n",
        "\n",
        "print(f\"\\nPrecision@{top_k}: {precision:.4f}\")\n",
        "print(f\"Recall@{top_k}: {recall:.4f}\")\n",
        "print(f\"F1 Score@{top_k}: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp3TXRg5p0w8",
        "outputId": "de2b806e-caff-4de3-ecba-33017de9f45a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Precision@10: 0.1000\n",
            "Recall@10: 0.0476\n",
            "F1 Score@10: 0.0645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_gcnn_neumf(customer_id, gcnn_model, neumf_model, data, adjacency_matrix, customer_to_index, items, top_k=10):\n",
        "    customer_idx = customer_to_index[customer_id]\n",
        "    num_items = len(items)\n",
        "\n",
        "    # ===== GCNN Predictions =====\n",
        "    gcnn_model.eval()\n",
        "    with torch.no_grad():\n",
        "        gcnn_scores = gcnn_model(data).view(-1)\n",
        "        gcnn_item_scores = gcnn_scores[len(customer_to_index):]  # Only item node predictions\n",
        "        gcnn_top_k_items = torch.topk(gcnn_item_scores, k=top_k).indices.tolist()\n",
        "        gcnn_stockcodes = [items[i] for i in gcnn_top_k_items]\n",
        "\n",
        "    # ===== NeuMF Predictions =====\n",
        "    neumf_model.eval()\n",
        "    with torch.no_grad():\n",
        "        item_indices = torch.arange(num_items)\n",
        "        user_tensor = torch.full((num_items,), customer_idx, dtype=torch.long)\n",
        "        neumf_scores = neumf_model(user_tensor, item_indices)\n",
        "        neumf_top_k_items = torch.topk(neumf_scores, k=top_k).indices.tolist()\n",
        "        neumf_stockcodes = [items[i] for i in neumf_top_k_items]\n",
        "\n",
        "    # ===== Actual Interactions =====\n",
        "    actual_indices = np.where(adjacency_matrix[customer_idx] > 0)[0]\n",
        "    actual_stockcodes = [items[i] for i in actual_indices]\n",
        "\n",
        "    # ===== Print Results =====\n",
        "    print(f\"\\n🧾 Recommendations for Customer ID {customer_id}\")\n",
        "    print(f\"GCNN  Top-{top_k} StockCodes:  {gcnn_stockcodes}\")\n",
        "    print(f\"NeuMF Top-{top_k} StockCodes:  {neumf_stockcodes}\")\n",
        "    print(f\"Actual StockCodes (Purchased): {actual_stockcodes}\")\n",
        "\n",
        "    # Optional: Calculate overlap\n",
        "    overlap = set(gcnn_stockcodes) & set(neumf_stockcodes)\n",
        "    print(f\"Overlap between GCNN and NeuMF: {overlap if overlap else 'None'}\")\n",
        "\n",
        "# 🔍 Call the function for customer 17850\n",
        "compare_gcnn_neumf(\n",
        "    customer_id=17850,\n",
        "    gcnn_model=gcnn_model,\n",
        "    neumf_model=neumf_model,\n",
        "    data=data,\n",
        "    adjacency_matrix=adjacency_matrix,\n",
        "    customer_to_index=customer_to_index,\n",
        "    items=items,\n",
        "    top_k=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShBThdJJtIvn",
        "outputId": "40d59a22-8cbe-4ccf-da02-f65ab9bb173d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧾 Recommendations for Customer ID 17850\n",
            "GCNN  Top-10 StockCodes:  [22423, '85123A', 47566, 21212, 22720, 84879, '85099B', 22960, 23298, 22457]\n",
            "NeuMF Top-10 StockCodes:  [85125, 37495, 23284, 23503, 21470, 22779, '35911B', 23418, 21220, '79063C']\n",
            "Actual StockCodes (Purchased): ['84029E', 71053, 21730, '84406B', 22752, '85123A', '84029G', 22633, 22632, 20679, 21068, 21871, 82483, 21071, 82486, 37370, '82494L', 82482, '15056BL', 22411, 22803]\n",
            "Overlap between GCNN and NeuMF: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison Summary\n",
        "Overlap Between GCNN & NeuMF:\n",
        "None. The two models produced completely different top-10 recommendations.\n",
        "\n",
        "Overlap with Actual Purchases:\n",
        "None of the top-10 recommended items from either GCNN or NeuMF appear in the actual purchases for customer 17850.\n",
        "\n",
        "Inference:\n",
        "\n",
        "Both models have distinct recommendation strategies. GCNN uses the graph structure of user-item interactions, while NeuMF relies on latent factor learning.\n",
        "\n",
        "Neither model captured the customer’s actual preferences well in this instance — likely due to:\n",
        "\n",
        "Sparse data for this customer.\n",
        "\n",
        "Cold start effects.\n",
        "\n",
        "Lack of side features (e.g., timestamps, categories)."
      ],
      "metadata": {
        "id": "gCwL9sZbtkYz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06lNrA-IjsPR"
      },
      "source": [
        "# Step 3: Discussion of Results [20 points]\n",
        "\n",
        "Discuss the performance of the GCNN model compared to the Feedforward NeuMF model. Provide insights on which model performs better and why, based on the evaluation metrics. Consider aspects like Precision@K, Recall@K, and F1 score.\n",
        "\n",
        "Compare the recommended items for Customer 17850 generated by your model with those recommended by Neo4j. Are there similarities between the two sets of recommendations?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "🧾 Recommendations for Customer ID 17850\n",
        "\n",
        "GCNN  Top-10 StockCodes:  [22423, '85123A', 47566, 21212, 22720, 84879, '85099B', 22960, 23298, 22457]\n",
        "\n",
        "NeuMF Top-10 StockCodes:  [85125, 37495, 23284, 23503, 21470, 22779, '35911B', 23418, 21220, '79063C']\n",
        "\n",
        "Actual StockCodes (Purchased): ['84029E', 71053, 21730, '84406B', 22752, '85123A', '84029G', 22633, 22632, 20679, 21068, 21871, 82483, 21071, 82486, 37370, '82494L', 82482, '15056BL', 22411, 22803]\n",
        "\n",
        "Overlap between GCNN and NeuMF: None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---------- Top 8 StockCodes bought by customer 17850 -----------\n",
        "\n",
        "     CustomerID StockCode  Quantity\n",
        "285       17850    82494L        12\n",
        "2629      17850    85123A        12\n",
        "2634      17850     71053        12\n",
        "2978      17850     71053        12\n",
        "2983      17850    85123A        12\n",
        "3299      17850     71053        12\n",
        "3301      17850     21068        12\n",
        "3302      17850    84029G        12\n",
        "\n",
        "------- Product Names of bought StockCodes ------\n",
        "\n",
        "135    Mediven Sheer and Soft 15-20 mmHg Thigh w/ Lac...\n",
        "162    Heavy Duty Handlebar Motorcycle Mount Holder K...\n",
        "179           AARCO Enclosed Wall Mounted Bulletin Board\n",
        "669    3 1/2\"W x 20\"D x 20\"H Funston Craftsman Smooth...\n",
        "967    Awkward Styles Shamrock Flag St. Patrick's Day...\n",
        "\n",
        "------------ Recommendations for Customer 17850 -----------\n",
        "\n",
        " Overlap with Actual Purchases\n",
        "\n",
        "✅ GCNN Recommendations:\n",
        "\n",
        "Top-10:\n",
        "[22423, '85123A', 47566, 21212, 22720, 84879, '85099B', 22960, 23298, 22457]\n",
        "\n",
        "\n",
        "Match: '85123A' is present in actual purchases, and frequently bought (multiple times, Quantity = 12).\n",
        "\n",
        "\n",
        "1 relevant hit, ranked 2nd — strong signal of relevance.\n",
        "\n",
        "\n",
        "❌ NeuMF (Neo4j) Recommendations:\n",
        "\n",
        "Top-10:\n",
        "[85125, 37495, 23284, 23503, 21470, 22779, '35911B', 23418, 21220, '79063C']\n",
        "\n",
        "\n",
        "No overlap with actual purchases.\n",
        "\n",
        "\n",
        "🔄 Overlap Between GCNN and NeuMF\n",
        "None: The two sets of recommendations have no StockCodes in common, indicating they’re likely using different latent structures or signals.\n",
        "\n",
        "\n",
        "📊 Interpretation\n",
        "\n",
        "✔ GCNN Performs Better\n",
        "GCNN correctly identifies '85123A' as a relevant item.\n",
        "\n",
        "\n",
        "'85123A' was purchased multiple times (at least twice in your sample).\n",
        "\n",
        "\n",
        "This StockCode may represent a popular or personally relevant product for this customer — suggesting GCNN captures user preferences more effectively.\n",
        "\n",
        "\n",
        "❌ NeuMF Misses the Target\n",
        "NeuMF fails to recommend any item from the customer’s history.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dWoMugOjT4Dt"
      }
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}