{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Objective:\n",
        "The goal of this exercise is to predict missing ratings in the Rating.csv dataset by iteratively updating missing values using regression models like decision trees or neural networks."
      ],
      "metadata": {
        "id": "lfSCCz4JtLAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Details:\n",
        "The dataset [Download here](https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database) contains the following columns:\n",
        "\n",
        "user_id: A randomly generated user ID (non-identifiable).\n",
        "anime_id: The ID of the anime rated by the user.\n",
        "rating: The rating the user assigned to the anime (range 1-10) or -1 if the user watched the anime but didnâ€™t provide a rating."
      ],
      "metadata": {
        "id": "N7C_GIZttRsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **# Steps for the Exercise:**\n",
        "\n",
        "# 1. Data Preparation:\n",
        "Load and Explore the Data:\n",
        "\n",
        "Load the dataset into a Pandas DataFrame.\n",
        "Explore the data to understand the structure, missing values (rating = -1), and general distribution."
      ],
      "metadata": {
        "id": "jNybcd64tWcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "Evg3QVTZ67Ar"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9gzQw_W2tKCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff77dfa8-fa14-4438-bfee-29e18c43f0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   user_id  anime_id  rating\n",
            "0        1      20.0    -1.0\n",
            "1        1      24.0    -1.0\n",
            "2        1      79.0    -1.0\n",
            "3        1     226.0    -1.0\n",
            "4        1     241.0    -1.0\n",
            "Missing data:\n",
            "          user_id  anime_id  rating\n",
            "0              1      20.0    -1.0\n",
            "1              1      24.0    -1.0\n",
            "2              1      79.0    -1.0\n",
            "3              1     226.0    -1.0\n",
            "4              1     241.0    -1.0\n",
            "...          ...       ...     ...\n",
            "5600660    52585    4793.0    -1.0\n",
            "5600661    52585    4874.0    -1.0\n",
            "5600663    52585    4910.0    -1.0\n",
            "5600664    52585    5526.0    -1.0\n",
            "5600696    52586       NaN     NaN\n",
            "\n",
            "[1072759 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/rating.csv\")\n",
        "print(data.head())\n",
        "missing_data = data[data['rating'].isin([-1, None])]\n",
        "print(\"Missing data:\\n\", missing_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Regression-Based Imputation (Iterative Approach):\n",
        "Setting Up the Regression Model:\n",
        "\n",
        "For simplicity, you can use a decision tree regression model to predict the missing values.\n",
        "Create a feature matrix (X) and target vector (y), where X consists of user_id, anime_id, and any other useful features (like user averages), and y is the rating."
      ],
      "metadata": {
        "id": "Gy-n2oZDuLAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# Filter out missing data (where rating == -1, treated as missing)\n",
        "train_data = data[data['rating'] != -1].copy()\n",
        "\n",
        "# Impute NaN values in user_avg_rating and anime_avg_rating with the overall average rating\n",
        "overall_avg_rating = train_data['rating'].mean()\n",
        "\n",
        "# Feature Engineering: Add user-based averages or anime-based averages\n",
        "train_data['user_avg_rating'] = train_data.groupby('user_id')['rating'].transform('mean') # Create 'user_avg_rating' column\n",
        "train_data['anime_avg_rating'] = train_data.groupby('anime_id')['rating'].transform('mean') # Create 'anime_avg_rating' column\n",
        "\n",
        "# *** Drop rows with NaN values in 'rating' column in train_data ***\n",
        "train_data = train_data.dropna(subset=['rating'])\n",
        "\n",
        "# Features: user_id, anime_id, user_avg_rating, anime_avg_rating\n",
        "X = train_data[['user_id', 'anime_id', 'user_avg_rating', 'anime_avg_rating']]\n",
        "y = train_data['rating']\n",
        "\n",
        "# Train-test split (to ensure good model performance evaluation)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "P_F0yvLd-2hD"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train a Regression Model (Decision Tree in this case):"
      ],
      "metadata": {
        "id": "PWPGv0sVudyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Decision Tree Regressor model\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model performance\n",
        "score = model.score(X_test, y_test)\n",
        "print(f\"Model R-squared score: {score}\")"
      ],
      "metadata": {
        "id": "SOZnZjEwuh_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e307631d-d6b6-459b-ab63-cc0063c34c69"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model R-squared score: -0.15653852553335712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Impute Missing Values Using the Trained Model:\n",
        "\n",
        "For each missing rating, predict it using the trained regression model.\n"
      ],
      "metadata": {
        "id": "0TDzOg8zukU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, predict ratings for the missing data (where rating == -1 or NaN)\n",
        "#missing_data = data[data['rating'].isin([-1, None])]  # Treat both -1 and NaN as missing\n",
        "# Now, predict ratings for the missing data (where rating == -1 or NaN)\n",
        "missing_data = data[data['rating'].isin([-1, None])].copy()\n",
        "\n",
        "# Calculate user_avg_rating and anime_avg_rating for missing_data\n",
        "missing_data['user_avg_rating'] = missing_data.groupby('user_id')['rating'].transform('mean')\n",
        "missing_data['anime_avg_rating'] = missing_data.groupby('anime_id')['rating'].transform('mean')\n",
        "\n",
        "X_missing = missing_data[['user_id', 'anime_id', 'user_avg_rating', 'anime_avg_rating']]\n",
        "# Predict the missing ratings\n",
        "predicted_ratings = model.predict(X_missing)\n",
        "\n",
        "\n",
        "# Update the DataFrame with the predicted ratings for missing values\n",
        "data.loc[missing_data.index, 'rating'] = predicted_ratings\n",
        "\n",
        "# Output the updated DataFrame\n",
        "print(\"\\nUpdated DataFrame with predicted ratings:\\n\", data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mQcFkY59l9F",
        "outputId": "b68d223c-1025-42bd-e3bb-14d759ef4d0c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated DataFrame with predicted ratings:\n",
            "          user_id  anime_id  rating\n",
            "0              1      20.0     1.0\n",
            "1              1      24.0     1.0\n",
            "2              1      79.0     1.0\n",
            "3              1     226.0     1.0\n",
            "4              1     241.0     1.0\n",
            "...          ...       ...     ...\n",
            "5600692    52586     356.0     8.0\n",
            "5600693    52586     431.0     9.0\n",
            "5600694    52586     440.0     9.0\n",
            "5600695    52586     523.0    10.0\n",
            "5600696    52586       NaN     8.0\n",
            "\n",
            "[5600697 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Repeat the Process:\n",
        "\n",
        "After updating the ratings, you can re-train the model with the newly imputed data and predict again, improving the quality of the imputed values."
      ],
      "metadata": {
        "id": "0BoOMu29uwr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterative imputation process\n",
        "max_iterations = 5  # Set the number of iterations for improving predictions\n",
        "\n",
        "for i in range(max_iterations):\n",
        "    print(f\"\\nIteration: {i+1}\")\n",
        "    # Now, predict ratings for the missing data (where rating == -1 or NaN)\n",
        "    missing_data = data[data['rating'].isin([-1, None])].copy()  # Treat both -1 and NaN as missing\n",
        "\n",
        "    if not missing_data.empty:\n",
        "        # Calculate user_avg_rating and anime_avg_rating for missing_data before prediction\n",
        "        #These need to be recalculated for the missing data based on the current data\n",
        "        missing_data['user_avg_rating'] = missing_data.groupby('user_id')['rating'].transform('mean')\n",
        "        missing_data['anime_avg_rating'] = missing_data.groupby('anime_id')['rating'].transform('mean')\n",
        "        X_missing = missing_data[['user_id', 'anime_id', 'user_avg_rating', 'anime_avg_rating']]\n",
        "\n",
        "        # Predict the missing ratings\n",
        "        predicted_ratings = model.predict(X_missing)\n",
        "\n",
        "        # Update the DataFrame with the predicted ratings for missing values\n",
        "        data.loc[missing_data.index, 'rating'] = predicted_ratings\n",
        "    else:\n",
        "        print(\"No missing data to impute in this iteration.\")\n",
        "\n",
        "    # Re-train the model with the updated data (including the imputed values)\n",
        "    train_data = data[data['rating'] != -1].copy()\n",
        "\n",
        "    #Recalculating the average rating columns after updating the DataFrame:\n",
        "    train_data['user_avg_rating'] = train_data.groupby('user_id')['rating'].transform('mean') # Create 'user_avg_rating' column\n",
        "    train_data['anime_avg_rating'] = train_data.groupby('anime_id')['rating'].transform('mean') # Create 'anime_avg_rating' column\n",
        "\n",
        "    X = train_data[['user_id', 'anime_id', 'user_avg_rating', 'anime_avg_rating']]\n",
        "    y = train_data['rating']\n",
        "\n",
        "    # Re-train the model on the updated data\n",
        "    if not X.empty and not y.empty:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        score = model.score(X_test, y_test)\n",
        "        print(f\"Model R-squared score after imputation: {score}\")\n",
        "    else:\n",
        "        print(\"No training data available for retraining.\")\n",
        "\n",
        "# After completing the iterations, print the final updated values\n",
        "print(\"\\nFinal Updated DataFrame with Imputed Ratings:\")\n",
        "print(data[['user_id', 'anime_id', 'rating']].head())  # Print the top rows with updated ratings for review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FVHg3C5-Tja",
        "outputId": "e982477a-a372-40e2-b2b1-a05b5e6b0685"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration: 1\n",
            "No missing data to impute in this iteration.\n",
            "Model R-squared score after imputation: 0.32265528233764806\n",
            "\n",
            "Iteration: 2\n",
            "No missing data to impute in this iteration.\n",
            "Model R-squared score after imputation: 0.32265528233764806\n",
            "\n",
            "Iteration: 3\n",
            "No missing data to impute in this iteration.\n",
            "Model R-squared score after imputation: 0.32265528233764806\n",
            "\n",
            "Iteration: 4\n",
            "No missing data to impute in this iteration.\n",
            "Model R-squared score after imputation: 0.32265528233764806\n",
            "\n",
            "Iteration: 5\n",
            "No missing data to impute in this iteration.\n",
            "Model R-squared score after imputation: 0.32265528233764806\n",
            "\n",
            "Final Updated DataFrame with Imputed Ratings:\n",
            "   user_id  anime_id  rating\n",
            "0        1      20.0     1.0\n",
            "1        1      24.0     1.0\n",
            "2        1      79.0     1.0\n",
            "3        1     226.0     1.0\n",
            "4        1     241.0     1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After completing the iterations, print the final updated values\n",
        "print(\"\\nFinal Updated DataFrame with Imputed Ratings:\")\n",
        "print(data[['user_id', 'anime_id', 'rating']].head())  # Print the top rows with updated ratings for review"
      ],
      "metadata": {
        "id": "BOkKEZzg0-20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6a8362-515a-4947-b6f8-b7fec51acf82"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Updated DataFrame with Imputed Ratings:\n",
            "   user_id  anime_id  rating\n",
            "0        1      20.0     1.0\n",
            "1        1      24.0     1.0\n",
            "2        1      79.0     1.0\n",
            "3        1     226.0     1.0\n",
            "4        1     241.0     1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluation:\n",
        "Measure Accuracy:\n",
        "\n",
        "After filling in missing ratings, evaluate how well the model performs on the imputed ratings.\n",
        "Use a root mean squared error (RMSE) or mean absolute error (MAE) to measure prediction accuracy."
      ],
      "metadata": {
        "id": "6OGtlUI9vDGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
        "print(f\"RMSE of model: {rmse}\")"
      ],
      "metadata": {
        "id": "AbJHhMMgvG8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8bd0ff-fada-4bfc-e53a-8586fa0a725d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of model: 2.496908921621391\n"
          ]
        }
      ]
    }
  ]
}