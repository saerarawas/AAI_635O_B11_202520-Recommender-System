{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_635O_B11_202520-Recommender-System/blob/main/Saera_Recommender_System_Course_Project_GitHub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pZyDezN6cLJ"
      },
      "source": [
        "# Graded Assessment -- AAI 6350 Recommender Systems Course --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrOzAVmq3pWB"
      },
      "source": [
        "# Part 1: Recommendation System Using GCNN [weight: 40\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCoSCUQqjEzp"
      },
      "source": [
        "# Step 1: Data Preparation\n",
        "- Load the Data: Read the Excel file and extract the relevant columns (CustomerID, StockCode, Quantity).\n",
        "- Data Cleaning: Ensure there are no missing values in the relevant columns.\n",
        "- Create Interaction Matrix: Construct an adjacency matrix where rows represent customers and columns represent items. The values in the matrix will be the quantities purchased."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Lc0BmAXOjBAH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(\"/content/Rec_sys_data.xlsx\")\n",
        "\n",
        "# Create a pivot table to form the interaction matrix\n",
        "interaction_matrix = data.pivot_table(index='CustomerID', columns='StockCode', values='Quantity', fill_value=0)\n",
        "\n",
        "# Convert to a NumPy array for further processing\n",
        "interaction_matrix = interaction_matrix.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmkY6QpXjRE8"
      },
      "source": [
        "# Step 2: Graph Construction [25 points]\n",
        "- Graph Representation: Each customer and item will be a node in the graph. An edge exists between a customer and an item if the customer has purchased that item.\n",
        "- Adjacency Matrix: Create an adjacency matrix where the rows represent customers and the columns represent items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AodAQLK-0vff",
        "outputId": "4a84e479-72e8-451d-8676-12d0f60d307e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the Adjacency Matrix (Customers x Items): (3647, 3538)\n",
            "\n",
            "First 5 rows of the Adjacency Matrix:\n",
            "[[1 1 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Adjacency DataFrame (first 5 rows and columns):\n",
            "       84029E  71053  21730  84406B  22752\n",
            "17850       1      1      1       1      1\n",
            "13047       0      0      0       0      0\n",
            "12583       0      0      0       0      0\n",
            "13748       0      0      0       0      0\n",
            "15100       0      0      0       0      0\n"
          ]
        }
      ],
      "source": [
        "# Get unique customers and items (StockCode)\n",
        "customers = data['CustomerID'].unique()\n",
        "items = data['StockCode'].unique()\n",
        "\n",
        "# Create mappings from customer/item IDs to matrix indices\n",
        "customer_to_index = {customer: i for i, customer in enumerate(customers)}\n",
        "item_to_index = {item: j for j, item in enumerate(items)}\n",
        "\n",
        "# Initialize the adjacency matrix with zeros\n",
        "num_customers = len(customers)\n",
        "num_items = len(items)\n",
        "adjacency_matrix = np.zeros((num_customers, num_items), dtype=int)\n",
        "\n",
        "# Populate the adjacency matrix: 1 if a customer purchased an item, 0 otherwise\n",
        "for index, row in data.iterrows():\n",
        "    customer_id = row['CustomerID']\n",
        "    item_id = row['StockCode']\n",
        "    if customer_id in customer_to_index and item_id in item_to_index:\n",
        "        customer_index = customer_to_index[customer_id]\n",
        "        item_index = item_to_index[item_id]\n",
        "        adjacency_matrix[customer_index, item_index] = 1\n",
        "\n",
        "# Print the shape of the adjacency matrix and a few rows to verify\n",
        "print(\"Shape of the Adjacency Matrix (Customers x Items):\", adjacency_matrix.shape)\n",
        "print(\"\\nFirst 5 rows of the Adjacency Matrix:\")\n",
        "print(adjacency_matrix[:5])\n",
        "\n",
        "# Optional: You can also create a DataFrame for better visualization if needed\n",
        "adjacency_df = pd.DataFrame(adjacency_matrix, index=customers, columns=items)\n",
        "print(\"\\nAdjacency DataFrame (first 5 rows and columns):\")\n",
        "print(adjacency_df.iloc[:5, :5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM779u1Mjf-0"
      },
      "source": [
        "# Step 3: Model Definition (GCNN) [35 points]\n",
        "- Define the GCNN Architecture: Use a library like PyTorch Geometric or TensorFlow with Keras to define the GCNN model.\n",
        "- The model will consist of graph convolutional layers that learn representations for both customers and items.\n",
        "- Prepare Data for Training: Convert the adjacency matrix and features into a format suitable for the GCNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FWDcffQe2XhY"
      },
      "outputs": [],
      "source": [
        "#!pip install torch-geometric torch-sparse torch-scatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITtBsxYa9S6n",
        "outputId": "af1b9be1-91ea-4070-9381-a5b4e229cea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Command '['/content/myenv/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n",
            "/bin/bash: line 1: myenvScriptsactivate: command not found\n",
            "Error: Command '['/content/myenv/bin/python3', '-m', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n",
            "/bin/bash: line 1: myenvScriptsactivate: command not found\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=3622720 sha256=2b71c16696e4fe1729d9eb58a5afc2cba66195821da11922d7740897f772b34f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp311-cp311-linux_x86_64.whl size=2846224 sha256=0c50630f4bcfac0cb8a9be352ef7811214b89a8c995f53b177d69ef472ce7a53\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e2/1e/299c596063839303657c211f587f05591891cc6cf126d94d21\n",
            "Successfully built torch-scatter torch-sparse\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1 torch-scatter-2.1.2 torch-sparse-0.6.18\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!python -m venv myenv\n",
        "!myenv\\Scripts\\activate  # On Windows\n",
        "!python -m venv myenv\n",
        "!myenv\\Scripts\\activate  # On Windows\n",
        "!pip install torch torchvision torchaudio  # Install PyTorch\n",
        "!pip install torch-scatter torch-sparse torch-geometric  # Install PyG\n",
        "!pip install torch torchvision torchaudio  # Install PyTorch\n",
        "!pip install torch-scatter torch-sparse torch-geometric  # Install PyG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXEQ57j69B5D",
        "outputId": "832aba80-44e0-4986-c4b0-6078d8047606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.1\n"
          ]
        }
      ],
      "source": [
        "import torch_geometric\n",
        "print(torch_geometric.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqqPW_xWjnLi",
        "outputId": "2d2e50cc-0143-4520-90a0-4f00723c2d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[7185, 3647], edge_index=[2, 385516])\n",
            "Node Feature Shape: torch.Size([7185, 3647])\n",
            "Edge Index Shape: torch.Size([2, 385516])\n",
            "\n",
            "GCNN Model:\n",
            "GCN(\n",
            "  (conv1): GCNConv(3647, 64)\n",
            "  (conv2): GCNConv(64, 32)\n",
            ")\n",
            "\n",
            "Output Embeddings Shape: torch.Size([7185, 32])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assume 'adjacency_matrix', 'customers', and 'items' are already created as in the previous step\n",
        "\n",
        "# 1. Define Node Features (Optional but Recommended)\n",
        "# For simplicity, we'll start without explicit features.\n",
        "# In a real-world scenario, you might have customer demographics, item descriptions, etc.\n",
        "# If you don't have features, you can use an identity matrix as initial node embeddings.\n",
        "\n",
        "num_customers = adjacency_matrix.shape[0]\n",
        "num_items = adjacency_matrix.shape[1]\n",
        "num_nodes = num_customers + num_items\n",
        "\n",
        "# Create initial node embeddings (identity matrix) if no other features are available\n",
        "customer_features = torch.eye(num_customers)\n",
        "item_features = torch.eye(num_items)\n",
        "#node_features = torch.cat([customer_features, item_features], dim=0).float()\n",
        "# Pad item_features with zeros to match customer_features shape\n",
        "padding_size = num_customers - num_items\n",
        "padding = torch.zeros(num_items, padding_size)  # Create a padding tensor\n",
        "item_features = torch.cat([item_features, padding], dim=1)  # Pad along dimension 1 (columns)\n",
        "\n",
        "node_features = torch.cat([customer_features, item_features], dim=0).float()\n",
        "# 2. Create Edge List (COO format) from the Adjacency Matrix\n",
        "# PyTorch Geometric uses the COO format for representing sparse graphs\n",
        "row_indices, col_indices = adjacency_matrix.nonzero()\n",
        "\n",
        "# Shift item indices to account for customer nodes\n",
        "edge_index_0 = torch.tensor(row_indices, dtype=torch.long)\n",
        "edge_index_1 = torch.tensor(col_indices + num_customers, dtype=torch.long)\n",
        "edge_index = torch.stack([edge_index_0, edge_index_1], dim=0)\n",
        "\n",
        "# Also create the reverse edges (item purchased by customer implies connection)\n",
        "reverse_edge_index_0 = torch.tensor(col_indices + num_customers, dtype=torch.long)\n",
        "reverse_edge_index_1 = torch.tensor(row_indices, dtype=torch.long)\n",
        "reverse_edge_index = torch.stack([reverse_edge_index_0, reverse_edge_index_1], dim=0)\n",
        "\n",
        "# Combine forward and reverse edges to create an undirected graph representation\n",
        "edge_index = torch.cat([edge_index, reverse_edge_index], dim=1)\n",
        "\n",
        "# 3. Create Labels (for a supervised learning task - you'll need to define your task)\n",
        "# For example, if you want to predict future purchases, you might need to create labels\n",
        "# based on temporal splits of your data.\n",
        "# For now, let's assume a simple task where the presence of an edge is the signal.\n",
        "# We might not need explicit labels in the same way as node/graph classification.\n",
        "\n",
        "# 4. Create the PyTorch Geometric Data object\n",
        "data = Data(x=node_features, edge_index=edge_index)\n",
        "\n",
        "# Print the Data object to see its structure\n",
        "print(data)\n",
        "print(\"Node Feature Shape:\", data.x.shape)\n",
        "print(\"Edge Index Shape:\", data.edge_index.shape)\n",
        "\n",
        "# 5. Define the GCNN Architecture\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_channels, num_embeddings):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, num_embeddings)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "hidden_channels = 64  # You can experiment with this\n",
        "embedding_dim = 32   # The dimensionality of the learned embeddings\n",
        "model = GCN(num_node_features=node_features.shape[1], hidden_channels=hidden_channels, num_embeddings=embedding_dim)\n",
        "\n",
        "print(\"\\nGCNN Model:\")\n",
        "print(model)\n",
        "\n",
        "# Example of a forward pass\n",
        "out = model(data.x, data.edge_index)\n",
        "print(\"\\nOutput Embeddings Shape:\", out.shape)\n",
        "# The first 'num_customers' rows of 'out' are the customer embeddings,\n",
        "# and the rest are the item embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG6dBRgXj4Q4"
      },
      "source": [
        "# Step 4: Training the Model [40 points]\n",
        "\n",
        "- Loss Function: Use a suitable loss function, such as Mean Squared Error (MSE) as we are working with continuous interaction scores.\n",
        "- Optimizer: Choose an optimizer like Adam or SGD.\n",
        "- Training Loop: Implement the training loop to update the model weights based on the loss. In each epoch, calculate the predictions using the model, compute the loss between predicted and actual values, and perform backpropagation to update the model's weights.\n",
        "- Also compute the validation loss to evaluate the model's performance on unseen data, and use early stopping to halt training when the validation loss stops improving, preventing overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9sO5AAKTNwzE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm  # For progress bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mPrABQHNbKk",
        "outputId": "6354b706-2e97-458a-c19d-b813da68ddf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Train Loss: 1.3863, Val Loss: 1.3671\n",
            "Epoch 2/200, Train Loss: 1.3642, Val Loss: 1.3242\n",
            "Epoch 3/200, Train Loss: 1.3105, Val Loss: 1.3439\n",
            "Epoch 4/200, Train Loss: 1.2865, Val Loss: 1.3745\n",
            "Epoch 5/200, Train Loss: 1.2994, Val Loss: 1.3113\n",
            "Epoch 6/200, Train Loss: 1.2651, Val Loss: 1.2872\n",
            "Epoch 7/200, Train Loss: 1.2633, Val Loss: 1.2823\n",
            "Epoch 8/200, Train Loss: 1.2645, Val Loss: 1.2726\n",
            "Epoch 9/200, Train Loss: 1.2533, Val Loss: 1.2635\n",
            "Epoch 10/200, Train Loss: 1.2367, Val Loss: 1.2652\n",
            "Epoch 11/200, Train Loss: 1.2274, Val Loss: 1.2773\n",
            "Epoch 12/200, Train Loss: 1.2276, Val Loss: 1.2614\n",
            "Epoch 13/200, Train Loss: 1.2177, Val Loss: 1.2332\n",
            "Epoch 14/200, Train Loss: 1.2043, Val Loss: 1.2170\n",
            "Epoch 15/200, Train Loss: 1.2021, Val Loss: 1.2093\n",
            "Epoch 16/200, Train Loss: 1.1970, Val Loss: 1.2023\n",
            "Epoch 17/200, Train Loss: 1.1842, Val Loss: 1.2078\n",
            "Epoch 18/200, Train Loss: 1.1804, Val Loss: 1.2093\n",
            "Epoch 19/200, Train Loss: 1.1781, Val Loss: 1.1956\n",
            "Epoch 20/200, Train Loss: 1.1688, Val Loss: 1.1798\n",
            "Epoch 21/200, Train Loss: 1.1638, Val Loss: 1.1772\n",
            "Epoch 22/200, Train Loss: 1.1626, Val Loss: 1.1772\n",
            "Epoch 23/200, Train Loss: 1.1561, Val Loss: 1.1867\n",
            "Epoch 24/200, Train Loss: 1.1541, Val Loss: 1.1920\n",
            "Epoch 25/200, Train Loss: 1.1537, Val Loss: 1.1838\n",
            "Epoch 26/200, Train Loss: 1.1525, Val Loss: 1.1856\n",
            "Epoch 27/200, Train Loss: 1.1525, Val Loss: 1.1876\n",
            "Epoch 28/200, Train Loss: 1.1498, Val Loss: 1.2016\n",
            "Epoch 29/200, Train Loss: 1.1480, Val Loss: 1.2112\n",
            "Epoch 30/200, Train Loss: 1.1511, Val Loss: 1.2014\n",
            "Epoch 31/200, Train Loss: 1.1486, Val Loss: 1.2032\n",
            "Epoch 32/200, Train Loss: 1.1498, Val Loss: 1.2064\n",
            "Early stopping triggered at epoch 32\n",
            "Training Finished!\n"
          ]
        }
      ],
      "source": [
        "# 1. Define Loss Function\n",
        "# For link prediction (reconstructing the adjacency), a common approach is to use\n",
        "# a loss based on the dot product of the embeddings of connected nodes.\n",
        "# We'll define a loss that encourages higher dot products for existing edges\n",
        "# and lower dot products for non-existent edges (though sampling negatives is more efficient).\n",
        "\n",
        "def link_prediction_loss(embeddings, edge_index):\n",
        "    # Positive examples: existing edges\n",
        "    src, dst = edge_index\n",
        "    positive_scores = torch.sum(embeddings[src] * embeddings[dst], dim=1)\n",
        "    positive_loss = -F.logsigmoid(positive_scores).mean()\n",
        "\n",
        "    # Simplified negative sampling (can be improved with random sampling)\n",
        "    num_edges = edge_index.size(1)\n",
        "    num_nodes = embeddings.size(0)\n",
        "    negative_src = torch.randint(0, num_nodes, (num_edges,))\n",
        "    negative_dst = torch.randint(0, num_nodes, (num_edges,))\n",
        "    negative_scores = torch.sum(embeddings[negative_src] * embeddings[negative_dst], dim=1)\n",
        "    negative_loss = -F.logsigmoid(-negative_scores).mean()\n",
        "\n",
        "    return positive_loss + negative_loss\n",
        "\n",
        "# 2. Define Optimizer\n",
        "learning_rate = 0.01\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3. Prepare Data for Training and Validation (Splitting Edges)\n",
        "# Splitting nodes might not be the best approach for graph-based tasks.\n",
        "# We'll split the edges into training and validation sets.\n",
        "\n",
        "num_edges = data.edge_index.size(1)\n",
        "train_edges, val_edges = train_test_split(torch.arange(num_edges).numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "train_edge_index = data.edge_index[:, train_edges]\n",
        "val_edge_index = data.edge_index[:, val_edges]\n",
        "\n",
        "# Create training and validation Data objects\n",
        "train_data = Data(x=data.x, edge_index=train_edge_index)\n",
        "val_data = Data(x=data.x, edge_index=val_edge_index)\n",
        "\n",
        "# 4. Implement Training Loop with Validation and Early Stopping\n",
        "num_epochs = 200\n",
        "patience = 10  # Number of epochs to wait for improvement\n",
        "best_val_loss = float('inf')\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    embeddings = model(train_data.x, train_data.edge_index)\n",
        "    loss = link_prediction_loss(embeddings, train_data.edge_index)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_embeddings = model(val_data.x, val_data.edge_index)\n",
        "        val_loss = link_prediction_loss(val_embeddings, val_data.edge_index)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        epochs_without_improvement = 0\n",
        "        # Optionally save the best model state here\n",
        "        # torch.save(model.state_dict(), 'best_gcn_model.pth')\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "# Optionally load the best model\n",
        "# model.load_state_dict(torch.load('best_gcn_model.pth'))\n",
        "\n",
        "print(\"Training Finished!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qGm-oBQ3w-y"
      },
      "source": [
        "# Part 2: Recommendation System Evaluation and Comparison Using GCNN and NeuMF Models [weight: 30\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Be3vugeLBvo"
      },
      "source": [
        "# Step 1: Evaluation [40 points]\n",
        "\n",
        "To calculate the average precision, recall, and F1 score for all customers, follow these steps:\n",
        "\n",
        "- Obtain Model Predictions: Use the trained model to predict interaction scores for all customer-item pairs in the validation set.\n",
        "\n",
        "- Rank Items by Predicted Scores: For each customer, rank items based on the predicted interaction scores in descending order.\n",
        "\n",
        "- Define Relevant Items: Set a threshold to determine which items are considered relevant (e.g., based on the top-k predictions or actual interactions greater than zero).\n",
        "\n",
        "- Calculate Precision, Recall, and F1 Score for Each Customer: For each customer, calculate precision, recall, and F1 score using the relevant predicted and actual items.\n",
        "\n",
        "- Compute Average Precision, Recall, and F1 Score: Calculate the mean of precision, recall, and F1 scores across all customers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpqfy7nHLG0D",
        "outputId": "6bc022c6-216f-48ef-9d82-662aa18ec1bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision@10: 0.0299\n",
            "Average Recall@10: 0.0299\n",
            "Average F1 Score@10: 0.0240\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assume 'model', 'val_data', 'customers', 'items', 'customer_to_index', 'item_to_index' are available\n",
        "\n",
        "# 1. Obtain Model Predictions for Validation Set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_embeddings = model(val_data.x, val_data.edge_index)\n",
        "    customer_embeddings = val_embeddings[:len(customers)]\n",
        "    item_embeddings = val_embeddings[len(customers):]\n",
        "\n",
        "# Create a dictionary to store actual interactions in the validation set for each customer\n",
        "actual_interactions = defaultdict(list)\n",
        "for edge_idx in range(val_data.edge_index.shape[1]):\n",
        "    u_idx = val_data.edge_index[0, edge_idx].item()\n",
        "    i_idx = val_data.edge_index[1, edge_idx].item() - len(customers) # Adjust item index\n",
        "\n",
        "    # Check if u_idx is within the bounds of the customers array\n",
        "    if u_idx < len(customers):\n",
        "        customer_id = customers[u_idx]\n",
        "    else:\n",
        "        # Handle the case where u_idx is out of bounds (e.g., skip or print a warning)\n",
        "        continue  # Skip this edge if it refers to an item node\n",
        "\n",
        "    # Check if i_idx is within the bounds of the items array\n",
        "    if 0 <= i_idx < len(items):\n",
        "        item_id = items[i_idx]\n",
        "    else:\n",
        "        # Handle the case where i_idx is out of bounds (e.g., skip or print a warning)\n",
        "        continue  # Skip this edge if it refers to an invalid item index\n",
        "\n",
        "    actual_interactions[customer_id].append(item_id)\n",
        "\n",
        "# Create a dictionary to store predicted scores for each customer-item pair in the validation set\n",
        "predicted_scores = defaultdict(dict)\n",
        "for i, customer_id in enumerate(customers):\n",
        "    customer_embed = customer_embeddings[i]\n",
        "    for j, item_id in enumerate(items):\n",
        "        item_embed = item_embeddings[j]\n",
        "        score = torch.dot(customer_embed, item_embed).item() # Using dot product as a proxy for interaction score\n",
        "        predicted_scores[customer_id][item_id] = score\n",
        "\n",
        "# 2. Rank Items by Predicted Scores for Each Customer\n",
        "ranked_predictions = defaultdict(list)\n",
        "for customer_id, item_scores in predicted_scores.items():\n",
        "    sorted_items = sorted(item_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    ranked_predictions[customer_id] = [item[0] for item in sorted_items]\n",
        "\n",
        "# 3. Define Relevant Items (Top-k approach)\n",
        "k = 10 # Consider top-k predicted items as relevant\n",
        "average_precision_sum = 0\n",
        "average_recall_sum = 0\n",
        "average_f1_sum = 0\n",
        "num_customers_evaluated = 0\n",
        "\n",
        "# 4. Calculate Precision, Recall, and F1 Score for Each Customer\n",
        "for customer_id in actual_interactions:\n",
        "    if customer_id in ranked_predictions:\n",
        "        actual_relevant = set(actual_interactions[customer_id])\n",
        "        top_k_predicted = set(ranked_predictions[customer_id][:k])\n",
        "\n",
        "        true_positives = len(actual_relevant.intersection(top_k_predicted))\n",
        "        predicted_positives = len(top_k_predicted)\n",
        "        actual_positives = len(actual_relevant)\n",
        "\n",
        "        # Calculate Precision\n",
        "        precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
        "\n",
        "        # Calculate Recall\n",
        "        recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
        "\n",
        "        # Calculate F1 Score\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        average_precision_sum += precision\n",
        "        average_recall_sum += recall\n",
        "        average_f1_sum += f1\n",
        "        num_customers_evaluated += 1\n",
        "\n",
        "# 5. Compute Average Precision, Recall, and F1 Score\n",
        "if num_customers_evaluated > 0:\n",
        "    avg_precision = average_precision_sum / num_customers_evaluated\n",
        "    avg_recall = average_recall_sum / num_customers_evaluated\n",
        "    avg_f1 = average_f1_sum / num_customers_evaluated\n",
        "else:\n",
        "    avg_precision = 0\n",
        "    avg_recall = 0\n",
        "    avg_f1 = 0\n",
        "\n",
        "print(f\"Average Precision@{k}: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall@{k}: {avg_recall:.4f}\")\n",
        "print(f\"Average F1 Score@{k}: {avg_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYvJq4c4iz2l"
      },
      "source": [
        "# Step 2: Generating Recommendations and Evaluating for a Specific Customer [40 points]\n",
        "\n",
        "1- Mapping Customer IDs to Indices.\n",
        "\n",
        "2- Get Predicted Scores for the Customer.\n",
        "\n",
        "3- Rank Items by Predicted Scores.\n",
        "\n",
        "4- Map Recommended Items to Stock Codes.\n",
        "\n",
        "5- Compare Recommendations with Actual Interactions.\n",
        "\n",
        "6- Calculate Precision, Recall, and F1 Score."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assume 'model', 'val_data', 'customers', 'items', 'customer_to_index', 'item_to_index' are available\n",
        "\n",
        "# Load product data for mapping StockCode to product names\n",
        "data_prod = pd.read_excel(\"/content/Rec_sys_data.xlsx\", sheet_name='product')\n",
        "item_titles = data_prod[['StockCode', 'Product Name']].drop_duplicates()\n",
        "item_titles_dict = dict(zip(item_titles['StockCode'], item_titles['Product Name']))\n"
      ],
      "metadata": {
        "id": "GNVaPFHcXb3F"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yKv8hUTu8r4",
        "outputId": "0e6cf87d-85c9-4112-f99b-f2bd3b264656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 Recommendations for Customer ID: 17850\n",
            "- 22423: Handcrafted Ercolano Music Box Featuring \"Luncheon of the Boating Party\" by Renoir, Pierre Auguste - New YorkNew York\n",
            "- 85123A: Mediven Sheer and Soft 15-20 mmHg Thigh w/ Lace Silicone Top Band CT Wheat II - Ankle 8-8.75 inches\n",
            "- 21212: 3 1/2\"W x 20\"D x 20\"H Funston Craftsman Smooth Bracket, Douglas Fir\n",
            "- 47566: Port Authority K110 Dry Zone UV Micro-Mesh Polo, Gusty Grey, S\n",
            "- 22720: MightySkins Skin Decal Wrap Compatible with DJI Sticker Protective Cover 100's of Color Options\n",
            "- 20725: billyboards Porcelain Menu Chalkboard\n",
            "- 22961: 1.30 Carat (ctw) 14K White Gold Round Diamond Ladies 3 Stone Bridal Engagement Ring Set With Band\n",
            "- 22960: Augusta 1235 Ladies Triumph Jersey\n",
            "- 85099B: Ebe Women Reading Glasses Reader Cheaters Anti Reflective Lenses TR90 ry2209\n",
            "- 23298: 3 1/2\"W x 20\"D x 20\"H Funston Craftsman Smooth Bracket, Douglas Fir\n",
            "\n",
            "Actual Interactions for Customer ID: 17850\n",
            "- 22633: Handcrafted Ercolano Music Box Featuring \"Luncheon of the Boating Party\" by Renoir, Pierre Auguste - New YorkNew York\n",
            "- 21730: Ebe Men Black Rectangle Half Rim Spring Hinge Eyewear Reading Glasses 2036\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# 2. Get Predicted Scores for the Customer\n",
        "def get_predicted_scores(model, customer_id, customers, items, customer_to_index, item_to_index, node_features, edge_index):\n",
        "    \"\"\"\n",
        "    Calculates predicted interaction scores for a given customer and all items.\n",
        "\n",
        "    Args:\n",
        "        model: Your trained PyTorch GCNN model.\n",
        "        customer_id: The ID of the customer for whom to generate predictions.\n",
        "        customers: List of all customer IDs.\n",
        "        items: List of all item IDs (StockCodes).\n",
        "        customer_to_index: Dictionary mapping customer IDs to their numerical indices.\n",
        "        item_to_index: Dictionary mapping item IDs to their numerical indices.\n",
        "        node_features: The node feature matrix (torch.Tensor) for the graph.\n",
        "        edge_index: The edge index tensor (torch.Tensor) representing the graph connections.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary where keys are item IDs (StockCodes) and values are the predicted scores.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode (important for inference)\n",
        "    with torch.no_grad():  # Disable gradient calculation to save memory and speed up inference\n",
        "        embeddings = model(node_features, edge_index)  # Get the node embeddings from the model\n",
        "        customer_embeddings = embeddings[:len(customers)]  # Separate customer embeddings\n",
        "        item_embeddings = embeddings[len(customers):]      # and item embeddings\n",
        "\n",
        "        if customer_id not in customer_to_index:\n",
        "            return {}  # Return an empty dictionary if the customer ID is not found\n",
        "\n",
        "        customer_index = customer_to_index[customer_id]  # Get the numerical index of the customer\n",
        "        customer_embed = customer_embeddings[customer_index]  # Get the embedding vector for the customer\n",
        "        item_scores = {}  # Initialize a dictionary to store item scores\n",
        "\n",
        "        for item_id, item_index in item_to_index.items():\n",
        "            item_embed = item_embeddings[item_index]  # Get the embedding vector for the item\n",
        "            score = torch.dot(customer_embed, item_embed).item()  # Calculate the dot product as the interaction score\n",
        "            item_scores[item_id] = score  # Store the score for the item\n",
        "\n",
        "        return item_scores\n",
        "\n",
        "# 3. Rank Items by Predicted Scores\n",
        "def rank_items_by_score(item_scores, top_n=10):\n",
        "    \"\"\"\n",
        "    Ranks items based on their predicted scores in descending order.\n",
        "\n",
        "    Args:\n",
        "        item_scores: A dictionary of item IDs (StockCodes) and their predicted scores.\n",
        "        top_n: The number of top-ranked items to return.  Defaults to 10.\n",
        "\n",
        "    Returns:\n",
        "        A list of (item_id, score) tuples, sorted in descending order of score, containing the top_n items.\n",
        "    \"\"\"\n",
        "    sorted_items = sorted(item_scores.items(), key=lambda item: item[1], reverse=True)  # Sort items by score\n",
        "    return sorted_items[:top_n]  # Return the top_n items\n",
        "# 4. Map Recommended Items to Stock Codes (Already the keys in the ranked list)\n",
        "# We will map to product names later if needed for display.\n",
        "# 5. Get Recommendations and Actual Interactions\n",
        "def get_recommendations_and_actual(customer_id, model, customers, items, customer_to_index, item_to_index, node_features, edge_index, val_data, k=10):\n",
        "    \"\"\"\n",
        "    Generates top-k recommendations for a customer and retrieves the actual items they interacted with in the validation data.\n",
        "\n",
        "    Args:\n",
        "        customer_id: The ID of the customer.\n",
        "        model: Your trained PyTorch GCNN model.\n",
        "        customers: List of all customer IDs.\n",
        "        items: List of all item IDs (StockCodes).\n",
        "        customer_to_index: Dictionary mapping customer IDs to their numerical indices.\n",
        "        item_to_index: Dictionary mapping item IDs to their numerical indices.\n",
        "        node_features: The node feature matrix (torch.Tensor).\n",
        "        edge_index: The edge index tensor (torch.Tensor).\n",
        "        val_data: The validation data (a PyTorch Geometric Data object or a dictionary-like object).  Crucially, it must have 'edge_index'.\n",
        "        k: The number of top recommendations to generate. Defaults to 10.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "        - A list of the top-k recommended item IDs (StockCodes).\n",
        "        - A list of the actual item IDs (StockCodes) the customer interacted with in the validation data.\n",
        "    \"\"\"\n",
        "    predicted_scores_for_customer = get_predicted_scores(model, customer_id, customers, items, customer_to_index, item_to_index, node_features, edge_index)\n",
        "    ranked_predictions = [item[0] for item in rank_items_by_score(predicted_scores_for_customer, top_n=k)]  # Get ranked item IDs\n",
        "\n",
        "    actual_relevant = set()  # Use a set for efficient membership checking\n",
        "    customer_index_val = customer_to_index.get(customer_id)  # Get the customer's index in the validation data\n",
        "    if customer_index_val is not None:\n",
        "        # Iterate through the edges in the validation data's edge_index\n",
        "        for edge_idx in range(val_data.edge_index.shape[1]):\n",
        "            u_idx_val = val_data.edge_index[0, edge_idx].item()  # Get the source node index (customer)\n",
        "            i_idx_val = val_data.edge_index[1, edge_idx].item() - len(customers)  # Get the target node index (item), adjusting for the offset\n",
        "            if u_idx_val == customer_index_val:  # If the edge involves the customer we're interested in\n",
        "                actual_relevant.add(items[i_idx_val])  # Add the item ID to the set of actual interactions\n",
        "\n",
        "    return ranked_predictions, list(actual_relevant)  # Return the recommendations and actual interactions\n",
        "\n",
        "# --- Assuming your model is trained and 'data' and 'val_data' are available ---\n",
        "# Load product data for mapping StockCode to product names\n",
        "try:\n",
        "    data_prod = pd.read_excel(\"/content/Rec_sys_data.xlsx\", sheet_name='product')\n",
        "    item_titles = data_prod[['StockCode', 'Product Name']].drop_duplicates()\n",
        "    item_titles_dict = dict(zip(item_titles['StockCode'], item_titles['Product Name']))\n",
        "except FileNotFoundError:\n",
        "    item_titles_dict = {}\n",
        "    print(\"Warning: 'Rec_sys_data.xlsx' not found. Product names will not be available.\")\n",
        "\n",
        "# Get recommendations for Customer ID 17850\n",
        "target_customer_id = 17850\n",
        "top_k = 10  # Number of recommendations to generate\n",
        "\n",
        "if 'model' in locals() and 'data' in locals() and 'val_data' in locals() and 'customers' in locals() and 'items' in locals() and 'customer_to_index' in locals() and 'item_to_index' in locals():\n",
        "    recommendations, actual_interactions = get_recommendations_and_actual(\n",
        "        target_customer_id, model, customers, items, customer_to_index, item_to_index, data.x, data.edge_index, val_data, k=top_k\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTop {top_k} Recommendations for Customer ID: {target_customer_id}\")\n",
        "    for stock_code in recommendations:\n",
        "        product_name = item_titles_dict.get(stock_code, \"Product Name Not Found\")\n",
        "        print(f\"- {stock_code}: {product_name}\")\n",
        "\n",
        "    print(f\"\\nActual Interactions for Customer ID: {target_customer_id}\")\n",
        "    for stock_code in actual_interactions:\n",
        "        product_name = item_titles_dict.get(stock_code, \"Product Name Not Found\")\n",
        "        print(f\"- {stock_code}: {product_name}\")\n",
        "else:\n",
        "    print(f\"Customer ID {target_customer_id} not found in the training data.\")\n",
        "\n",
        "#else:\n",
        "#    print(\"Error:  Make sure that 'model', 'data', 'val_data', 'customers', 'items', 'customer_to_index', and 'item_to_index' are defined and that your model is trained.\")\n",
        "#    print(\"  This code assumes you have already loaded your data and trained your GCNN model.\")\n",
        "# You can still run the evaluation for all customers if you want:\n",
        "if 'model' in locals() and 'data' in locals() and 'val_data' in locals() and 'customers' in locals() and 'items' in locals() and 'customer_to_index' in locals() and 'item_to_index' in locals():\n",
        "    avg_precision_at_k, avg_recall_at_k, avg_f1_at_k, all_customer_results = evaluate_all_customers(\n",
        "        model, customers, items, customer_to_index, item_to_index, data.x, data.edge_index, val_data, k=10\n",
        "    )\n",
        "\n",
        "    print(f\"\\nAverage Precision@10: {avg_precision_at_k:.4f}\")\n",
        "    print(f\"Average Recall@10: {avg_recall_at_k:.4f}\")\n",
        "    print(f\"Average F1 Score@10: {avg_f1_at_k:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Evaluate Model Performance\n",
        "if 'model' in locals() and 'data' in locals() and 'val_data' in locals() and 'customers' in locals() and 'items' in locals() and 'customer_to_index' in locals() and 'item_to_index' in locals():\n",
        "    avg_precision_at_k, avg_recall_at_k, avg_f1_at_k, all_customer_results = evaluate_all_customers(\n",
        "        model, customers, items, customer_to_index, item_to_index, data.x, data.edge_index, val_data, k=10\n",
        "    )\n",
        "\n",
        "    print(f\"\\nAverage Precision@10: {avg_precision_at_k:.4f}\")\n",
        "    print(f\"Average Recall@10: {avg_recall_at_k:.4f}\")\n",
        "    print(f\"Average F1 Score@10: {avg_f1_at_k:.4f}\")"
      ],
      "metadata": {
        "id": "n9cKt3UegMvB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06lNrA-IjsPR"
      },
      "source": [
        "# Step 3: Discussion of Results [20 points]\n",
        "\n",
        "Discuss the performance of the GCNN model compared to the Feedforward NeuMF model. Provide insights on which model performs better and why, based on the evaluation metrics. Consider aspects like Precision@K, Recall@K, and F1 score.\n",
        "\n",
        "Compare the recommended items for Customer 17850 generated by your model with those recommended by Neo4j. Are there similarities between the two sets of recommendations?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}