{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_635O_B11_202520-Recommender-System/blob/main/Week/Saera__Rawas_Recommender_System_Course_Project_GitHub_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pZyDezN6cLJ"
      },
      "source": [
        "# Graded Assessment -- AAI 6350 Recommender Systems Course --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrOzAVmq3pWB"
      },
      "source": [
        "# Part 1: Recommendation System Using GCNN [weight: 40\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCoSCUQqjEzp"
      },
      "source": [
        "# Step 1: Data Preparation\n",
        "- Load the Data: Read the Excel file and extract the relevant columns (CustomerID, StockCode, Quantity).\n",
        "- Data Cleaning: Ensure there are no missing values in the relevant columns.\n",
        "- Create Interaction Matrix: Construct an adjacency matrix where rows represent customers and columns represent items. The values in the matrix will be the quantities purchased."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc0BmAXOjBAH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(\"/content/Rec_sys_data.xlsx\")\n",
        "\n",
        "# Create a pivot table to form the interaction matrix\n",
        "interaction_matrix = data.pivot_table(index='CustomerID', columns='StockCode', values='Quantity', fill_value=0)\n",
        "\n",
        "# Convert to a NumPy array for further processing\n",
        "interaction_matrix = interaction_matrix.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmkY6QpXjRE8"
      },
      "source": [
        "# Step 2: Graph Construction [25 points]\n",
        "- Graph Representation: Each customer and item will be a node in the graph. An edge exists between a customer and an item if the customer has purchased that item.\n",
        "- Adjacency Matrix: Create an adjacency matrix where the rows represent customers and the columns represent items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AodAQLK-0vff",
        "outputId": "0878f0f2-3d8b-4f6c-d232-5a3bcc0a0ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the Adjacency Matrix (Customers x Items): (3647, 3538)\n",
            "\n",
            "First 5 rows of the Adjacency Matrix:\n",
            "[[1 1 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "\n",
            "Adjacency DataFrame (first 5 rows and columns):\n",
            "       84029E  71053  21730  84406B  22752\n",
            "17850       1      1      1       1      1\n",
            "13047       0      0      0       0      0\n",
            "12583       0      0      0       0      0\n",
            "13748       0      0      0       0      0\n",
            "15100       0      0      0       0      0\n"
          ]
        }
      ],
      "source": [
        "# Get unique customers and items (StockCode)\n",
        "customers = data['CustomerID'].unique()\n",
        "items = data['StockCode'].unique()\n",
        "\n",
        "# Create mappings from customer/item IDs to matrix indices\n",
        "customer_to_index = {customer: i for i, customer in enumerate(customers)}\n",
        "item_to_index = {item: j for j, item in enumerate(items)}\n",
        "\n",
        "# Initialize the adjacency matrix with zeros\n",
        "num_customers = len(customers)\n",
        "num_items = len(items)\n",
        "adjacency_matrix = np.zeros((num_customers, num_items), dtype=int)\n",
        "\n",
        "# Populate the adjacency matrix: 1 if a customer purchased an item, 0 otherwise\n",
        "for index, row in data.iterrows():\n",
        "    customer_id = row['CustomerID']\n",
        "    item_id = row['StockCode']\n",
        "    if customer_id in customer_to_index and item_id in item_to_index:\n",
        "        customer_index = customer_to_index[customer_id]\n",
        "        item_index = item_to_index[item_id]\n",
        "        adjacency_matrix[customer_index, item_index] = 1\n",
        "\n",
        "# Print the shape of the adjacency matrix and a few rows to verify\n",
        "print(\"Shape of the Adjacency Matrix (Customers x Items):\", adjacency_matrix.shape)\n",
        "print(\"\\nFirst 5 rows of the Adjacency Matrix:\")\n",
        "print(adjacency_matrix[:5])\n",
        "\n",
        "# Create a DataFrame for better visualization if needed\n",
        "adjacency_df = pd.DataFrame(adjacency_matrix, index=customers, columns=items)\n",
        "print(\"\\nAdjacency DataFrame (first 5 rows and columns):\")\n",
        "print(adjacency_df.iloc[:5, :5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM779u1Mjf-0"
      },
      "source": [
        "# Step 3: Model Definition (GCNN) [35 points]\n",
        "- Define the GCNN Architecture: Use a library like PyTorch Geometric or TensorFlow with Keras to define the GCNN model.\n",
        "- The model will consist of graph convolutional layers that learn representations for both customers and items.\n",
        "- Prepare Data for Training: Convert the adjacency matrix and features into a format suitable for the GCNN."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4gReGdbmsnL",
        "outputId": "9e80641d-02e9-4963-c263-b649a070f4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch_scatter 2.1.2+pt26cu124\n",
            "Uninstalling torch_scatter-2.1.2+pt26cu124:\n",
            "  Successfully uninstalled torch_scatter-2.1.2+pt26cu124\n",
            "Found existing installation: torch_sparse 0.6.18+pt26cu124\n",
            "Uninstalling torch_sparse-0.6.18+pt26cu124:\n",
            "  Successfully uninstalled torch_sparse-0.6.18+pt26cu124\n",
            "Found existing installation: torch-geometric 2.7.0\n",
            "Uninstalling torch-geometric-2.7.0:\n",
            "  Successfully uninstalled torch-geometric-2.7.0\n",
            "Found existing installation: torch_cluster 1.6.3+pt26cu124\n",
            "Uninstalling torch_cluster-1.6.3+pt26cu124:\n",
            "  Successfully uninstalled torch_cluster-1.6.3+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-scatter\n",
            "  Using cached https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-sparse\n",
            "  Using cached https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt26cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-cluster\n",
            "  Using cached https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt26cu124\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-tgo3vs4q\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-tgo3vs4q\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 492a6b76c738b7e53fa50211b8e6e327b9ef085d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.7.0) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.7.0) (2025.1.31)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1205197 sha256=0bf063fb35c383d2f89454ba78fd3f623cf69d1f54ea48c89cee17e69b1cabae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wvgywule/wheels/93/bb/85/bfec4ee59b2563f74ec87cc2c91c6a4d3e40d3dcdec8ee5afe\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Convert adjacency matrix to edge list (source and target)\n",
        "edges = []\n",
        "\n",
        "for customer_index in range(num_customers):\n",
        "    for item_index in range(num_items):\n",
        "        if adjacency_matrix[customer_index, item_index] == 1:\n",
        "            edges.append([customer_index, num_customers + item_index])  # Customer nodes: 0 to num_customers-1, Item nodes: num_customers to num_customers+num_items-1\n",
        "\n",
        "edges = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "\n",
        "# If you don't have additional features, you can just use ones as dummy features\n",
        "customer_features = torch.ones(num_customers, 1)  # Example: all customers having the same feature\n",
        "item_features = torch.ones(num_items, 1)  # Example: all items having the same feature\n",
        "node_features = torch.cat([customer_features, item_features], dim=0)  # Concatenate customer and item features\n",
        "\n",
        "# Create the Data object (PyTorch Geometric format)\n",
        "data = Data(x=node_features, edge_index=edges)\n"
      ],
      "metadata": {
        "id": "NVpPG-01h9rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "class GCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNN, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_channels, out_channels)\n",
        "        self.fc = nn.Linear(out_channels, 1)  # Output a single prediction (e.g., purchase likelihood)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply first convolutional layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Apply second convolutional layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Apply a fully connected layer (optional)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "HqYUMDMth_pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "# Set model, optimizer, and loss function\n",
        "model = GCNN(in_channels=1, hidden_channels=64, out_channels=32)  # Example channel sizes\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary classification (purchase/no-purchase)\n",
        "\n",
        "# Example training loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    out = model(data)\n",
        "\n",
        "    # Get edge indices\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # Create target tensor based on edges\n",
        "    target = torch.tensor(adjacency_matrix[edge_index[0], edge_index[1] - num_customers], dtype=torch.float)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = criterion(out[edge_index[0]].view(-1), target.view(-1)) # Select predictions for edges only\n",
        "\n",
        "    # Backpropagate\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYNMpCvKiBxB",
        "outputId": "1c3d08c4-e867-4b5c-8698-8a575d75d6e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7085666656494141\n",
            "Epoch 10, Loss: 0.09228347986936569\n",
            "Epoch 20, Loss: 0.000785060110501945\n",
            "Epoch 30, Loss: 2.6711670216172934e-05\n",
            "Epoch 40, Loss: 4.004476068075746e-06\n",
            "Epoch 50, Loss: 9.940775953509728e-07\n",
            "Epoch 60, Loss: 3.4912361002170655e-07\n",
            "Epoch 70, Loss: 1.7277960751016508e-07\n",
            "Epoch 80, Loss: 1.109426577272643e-07\n",
            "Epoch 90, Loss: 8.105943294367535e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(data)\n",
        "    predictions = torch.sigmoid(predictions).view(-1)  # Convert logits to probabilities\n"
      ],
      "metadata": {
        "id": "VrzjAbUxiDgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG6dBRgXj4Q4"
      },
      "source": [
        "# Step 4: Training the Model [40 points]\n",
        "\n",
        "- Loss Function: Use a suitable loss function, such as Mean Squared Error (MSE) as we are working with continuous interaction scores.\n",
        "- Optimizer: Choose an optimizer like Adam or SGD.\n",
        "- Training Loop: Implement the training loop to update the model weights based on the loss. In each epoch, calculate the predictions using the model, compute the loss between predicted and actual values, and perform backpropagation to update the model's weights.\n",
        "- Also compute the validation loss to evaluate the model's performance on unseen data, and use early stopping to halt training when the validation loss stops improving, preventing overfitting."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# 1. Prepare the data with proper train/val split\n",
        "# Convert edge indices and features to numpy first\n",
        "edge_index_np = data.edge_index.numpy().T\n",
        "edge_labels = torch.tensor(adjacency_matrix[edge_index_np[:, 0], edge_index_np[:, 1] - num_customers], dtype=torch.float)\n",
        "\n",
        "# Split edges into train and validation sets\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(edge_index_np.shape[0]),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_edge_index = torch.tensor(edge_index_np[train_idx], dtype=torch.long).t().contiguous()\n",
        "val_edge_index = torch.tensor(edge_index_np[val_idx], dtype=torch.long).t().contiguous()\n",
        "\n",
        "train_labels = edge_labels[train_idx]\n",
        "val_labels = edge_labels[val_idx]\n",
        "\n",
        "# 2. Modify the model for regression (since you mentioned continuous scores)\n",
        "class GCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNN, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_channels, out_channels)\n",
        "        self.fc = nn.Linear(out_channels, 1)\n",
        "\n",
        "    def forward(self, data, edge_index=None):\n",
        "        x, full_edge_index = data.x, data.edge_index\n",
        "        edge_index = full_edge_index if edge_index is None else edge_index\n",
        "\n",
        "        x = self.conv1(x, full_edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, full_edge_index)\n",
        "        x = torch.relu(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# 3. Initialize model, optimizer, and loss\n",
        "model = GCNN(in_channels=1, hidden_channels=64, out_channels=32)\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()  # For continuous interaction scores\n",
        "\n",
        "# 4. Training loop with early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass on training edges\n",
        "preds = model(data, train_edge_index)\n",
        "\n",
        "# Get predictions only for the relevant edges\n",
        "train_preds = preds[train_edge_index[0]].view(-1) # Select predictions for edges only\n",
        "\n",
        "# Calculate the loss using only the predictions for the edges in the training dataset\n",
        "train_loss = criterion(train_preds, train_labels)\n",
        "# Backpropagation\n",
        "train_loss.backward()\n",
        "optimizer.step()\n",
        "# Validation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_preds = model(data, val_edge_index) # Get predictions only for validation edges\n",
        "    val_loss = criterion(val_preds[val_edge_index[0]].view(-1), val_labels) # Select predictions for edges only and compare with labels\n",
        "# Early stopping check\n",
        "if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "else:\n",
        "        patience_counter += 1\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "# 1. Prepare the data with proper train/val split\n",
        "# Convert edge indices and features to numpy first\n",
        "edge_index_np = data.edge_index.numpy().T\n",
        "edge_labels = torch.tensor(adjacency_matrix[edge_index_np[:, 0], edge_index_np[:, 1] - num_customers], dtype=torch.float)\n",
        "\n",
        "# Split edges into train and validation sets\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(edge_index_np.shape[0]),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_edge_index = torch.tensor(edge_index_np[train_idx], dtype=torch.long).t().contiguous()\n",
        "val_edge_index = torch.tensor(edge_index_np[val_idx], dtype=torch.long).t().contiguous()\n",
        "\n",
        "train_labels = edge_labels[train_idx]\n",
        "val_labels = edge_labels[val_idx]\n",
        "\n",
        "# 2. Modify the model for regression (since you mentioned continuous scores)\n",
        "class GCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNN, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_channels, out_channels)\n",
        "        self.fc = nn.Linear(out_channels, 1)\n",
        "\n",
        "    def forward(self, data, edge_index=None):\n",
        "        x, full_edge_index = data.x, data.edge_index\n",
        "        edge_index = full_edge_index if edge_index is None else edge_index\n",
        "\n",
        "        x = self.conv1(x, full_edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, full_edge_index)\n",
        "        x = torch.relu(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# 3. Initialize model, optimizer, and loss\n",
        "model = GCNN(in_channels=1, hidden_channels=64, out_channels=32)\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()  # For continuous interaction scores\n",
        "\n",
        "# 4. Training loop with early stopping\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass on training edges\n",
        "    preds = model(data, train_edge_index)\n",
        "\n",
        "    # Get predictions only for the relevant edges\n",
        "    train_preds = preds[train_edge_index[0]].view(-1) # Select predictions for edges only\n",
        "\n",
        "    # Calculate the loss using only the predictions for the edges in the training dataset\n",
        "    train_loss = criterion(train_preds, train_labels)\n",
        "    # Backpropagation\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_preds = model(data, val_edge_index) # Get predictions only for validation edges\n",
        "        val_loss = criterion(val_preds[val_edge_index[0]].view(-1), val_labels) # Select predictions for edges only and compare with labels\n",
        "    # Early stopping check\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f'Epoch {epoch}: Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdIg9--r2j62",
        "outputId": "c8c5480d-7555-4d18-a3c2-2bbc70672a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Train Loss: 0.7561, Val Loss: 0.5544\n",
            "Epoch 5: Train Loss: 0.0045, Val Loss: 0.0230\n",
            "Early stopping at epoch 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qGm-oBQ3w-y"
      },
      "source": [
        "# Part 2: Recommendation System Evaluation and Comparison Using GCNN and NeuMF Models [weight: 30\\%]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Be3vugeLBvo"
      },
      "source": [
        "# Step 1: Evaluation [40 points]\n",
        "\n",
        "To calculate the average precision, recall, and F1 score for all customers, follow these steps:\n",
        "\n",
        "- Obtain Model Predictions: Use the trained model to predict interaction scores for all customer-item pairs in the validation set.\n",
        "\n",
        "- Rank Items by Predicted Scores: For each customer, rank items based on the predicted interaction scores in descending order.\n",
        "\n",
        "- Define Relevant Items: Set a threshold to determine which items are considered relevant (e.g., based on the top-k predictions or actual interactions greater than zero).\n",
        "\n",
        "- Calculate Precision, Recall, and F1 Score for Each Customer: For each customer, calculate precision, recall, and F1 score using the relevant predicted and actual items.\n",
        "\n",
        "- Compute Average Precision, Recall, and F1 Score: Calculate the mean of precision, recall, and F1 scores across all customers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(data).view(-1)  # Get raw scores\n"
      ],
      "metadata": {
        "id": "o67OMkQCpHka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Dictionaries to store predictions and ground truth per customer\n",
        "predictions_per_customer = defaultdict(list)\n",
        "actuals_per_customer = defaultdict(set)\n",
        "\n",
        "# Use val_edge_index instead of val_edges\n",
        "for i in range(val_edge_index.shape[1]):\n",
        "    customer_idx = val_edge_index[0, i].item()\n",
        "    item_idx = val_edge_index[1, i].item() - num_customers  # Convert to item index\n",
        "\n",
        "    score = output[val_edge_index[0, i]].item()  # Predicted score\n",
        "    actual = adjacency_matrix[customer_idx, item_idx]\n",
        "\n",
        "    predictions_per_customer[customer_idx].append((item_idx, score))\n",
        "    if actual > 0:\n",
        "        actuals_per_customer[customer_idx].add(item_idx)\n"
      ],
      "metadata": {
        "id": "JjyaxFeSpK8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def precision_recall_f1(y_true, y_pred):\n",
        "    if not y_pred:\n",
        "        return 0.0, 0.0, 0.0\n",
        "    y_true_bin = [1 if item in y_true else 0 for item in y_pred]\n",
        "    y_pred_bin = [1] * len(y_pred)\n",
        "\n",
        "    tp = sum(y_true_bin)\n",
        "    precision = tp / len(y_pred)\n",
        "    recall = tp / len(y_true) if y_true else 0.0\n",
        "    f1 = (2 * precision * recall) / (precision + recall + 1e-8)  # Avoid divide by zero\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Store all scores\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "\n",
        "k = 10  # Top-k items to recommend\n",
        "\n",
        "for customer, predictions in predictions_per_customer.items():\n",
        "    predictions_sorted = sorted(predictions, key=lambda x: x[1], reverse=True)\n",
        "    top_k_items = [item for item, score in predictions_sorted[:k]]\n",
        "    actual_items = actuals_per_customer[customer]\n",
        "\n",
        "    p, r, f = precision_recall_f1(actual_items, top_k_items)\n",
        "    precision_list.append(p)\n",
        "    recall_list.append(r)\n",
        "    f1_list.append(f)\n",
        "\n",
        "# Compute averages\n",
        "avg_precision = np.mean(precision_list)\n",
        "avg_recall = np.mean(recall_list)\n",
        "avg_f1 = np.mean(f1_list)\n",
        "\n",
        "print(f\"Average Precision@{k}: {avg_precision:.4f}\")\n",
        "print(f\"Average Recall@{k}: {avg_recall:.4f}\")\n",
        "print(f\"Average F1 Score@{k}: {avg_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jElbrjRgpOKB",
        "outputId": "e4aa4974-c9c0-425b-9d38-0355ab21790b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision@10: 1.0000\n",
            "Average Recall@10: 0.8408\n",
            "Average F1 Score@10: 0.8872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "class GCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNN, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_channels, out_channels)\n",
        "        self.fc = nn.Linear(out_channels, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = torch.relu(self.conv1(x, edge_index))\n",
        "        x = torch.relu(self.conv2(x, edge_index))\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "5vw9TrWnqiuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_gcnn(model, data, adjacency_matrix, num_customers, num_items, top_k=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        scores = model(data).view(-1)\n",
        "\n",
        "    item_scores = scores[num_customers:]  # Item nodes only\n",
        "\n",
        "    precision_list, recall_list, f1_list = [], [], []\n",
        "\n",
        "    for cust_idx in range(num_customers):\n",
        "        actual_indices = np.where(adjacency_matrix[cust_idx] > 0)[0]\n",
        "        if len(actual_indices) == 0:\n",
        "            continue  # Skip customers with no purchases\n",
        "\n",
        "        predicted_scores = item_scores  # Same for all customers\n",
        "        top_k_items = torch.topk(predicted_scores, k=top_k).indices.tolist()\n",
        "\n",
        "        actual_set = set(actual_indices)\n",
        "        pred_set = set(top_k_items)\n",
        "\n",
        "        tp = len(actual_set & pred_set)\n",
        "        precision = tp / top_k\n",
        "        recall = tp / len(actual_set)\n",
        "        f1 = (2 * precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "    return np.mean(precision_list), np.mean(recall_list), np.mean(f1_list)\n"
      ],
      "metadata": {
        "id": "SWXthip1qlT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuMF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim=32):\n",
        "        super(NeuMF, self).__init__()\n",
        "        self.user_embed = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embed = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * embedding_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, user_indices, item_indices):\n",
        "        u = self.user_embed(user_indices)\n",
        "        v = self.item_embed(item_indices)\n",
        "        x = torch.cat([u, v], dim=-1)\n",
        "        return self.mlp(x).squeeze()\n"
      ],
      "metadata": {
        "id": "WeJjRy2KqoOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_neumf(model, adjacency_matrix, top_k=10):\n",
        "    model.eval()\n",
        "    precision_list, recall_list, f1_list = [], [], []\n",
        "\n",
        "    num_users, num_items = adjacency_matrix.shape\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for user in range(num_users):\n",
        "            actual_items = np.where(adjacency_matrix[user] > 0)[0]\n",
        "            if len(actual_items) == 0:\n",
        "                continue\n",
        "\n",
        "            item_indices = torch.arange(num_items)\n",
        "            user_tensor = torch.full((num_items,), user, dtype=torch.long)\n",
        "\n",
        "            scores = model(user_tensor, item_indices)\n",
        "            top_items = torch.topk(scores, k=top_k).indices.tolist()\n",
        "\n",
        "            actual_set = set(actual_items)\n",
        "            pred_set = set(top_items)\n",
        "\n",
        "            tp = len(actual_set & pred_set)\n",
        "            precision = tp / top_k\n",
        "            recall = tp / len(actual_set)\n",
        "            f1 = (2 * precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "            precision_list.append(precision)\n",
        "            recall_list.append(recall)\n",
        "            f1_list.append(f1)\n",
        "\n",
        "    return np.mean(precision_list), np.mean(recall_list), np.mean(f1_list)\n"
      ],
      "metadata": {
        "id": "2YZXxMTrqqJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcnn_model = GCNN(in_channels=1, hidden_channels=64, out_channels=32) # Example channel sizes\n",
        "gcnn_data = data\n",
        "\n",
        "# Example usage after training both models:\n",
        "gcnn_p, gcnn_r, gcnn_f1 = evaluate_gcnn(gcnn_model, gcnn_data, adjacency_matrix, num_customers, num_items)\n",
        "print(f\"GCNN -> Precision@10: {gcnn_p:.4f}, Recall@10: {gcnn_r:.4f}, F1: {gcnn_f1:.4f}\")\n",
        "\n",
        "# Make sure num_customers and num_items are defined\n",
        "neumf_model = NeuMF(num_users=num_customers, num_items=num_items)\n",
        "\n",
        "neumf_p, neumf_r, neumf_f1 = evaluate_neumf(neumf_model, adjacency_matrix)\n",
        "print(f\"NeuMF -> Precision@10: {neumf_p:.4f}, Recall@10: {neumf_r:.4f}, F1: {neumf_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE6PPG1mqr9P",
        "outputId": "ba881ab5-adc6-435e-897e-013a4dd2cf65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCNN -> Precision@10: 0.0003, Recall@10: 0.0001, F1: 0.0001\n",
            "NeuMF -> Precision@10: 0.0135, Recall@10: 0.0023, F1: 0.0035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Comparison: GCNN vs. NeuMF for Recommender Systems\n",
        "Metric Analysis\n",
        "The evaluation metrics show a significant performance gap between the two models:\n",
        "\n",
        "Metric\t      GCNN\t  NeuMF\t  Relative Improvement\n",
        "Precision@10\t0.0003\t0.0135\t44x better\n",
        "Recall@10\t    0.0001\t0.0023\t23x better\n",
        "F1 Score\t    0.0001\t0.0035\t35x better\n",
        "Key Observations\n",
        "Dramatic Performance Difference:\n",
        "\n",
        "NeuMF outperforms GCNN by 1-2 orders of magnitude across all metrics\n",
        "\n",
        "The GCNN's near-zero metrics suggest it's essentially not functioning as a recommender\n",
        "\n",
        "Recommendation Quality:\n",
        "\n",
        "NeuMF's Precision@10 (1.35%) means ~1 in 100 recommended items are relevant\n",
        "\n",
        "GCNN's Precision@10 (0.03%) means only ~3 in 10,000 recommendations are relevant\n",
        "\n",
        "Coverage Ability:\n",
        "\n",
        "NeuMF's Recall@10 (0.23%) shows it finds some relevant items\n",
        "\n",
        "GCNN's Recall@10 (0.01%) indicates it's missing nearly all relevant items\n",
        "\n",
        "Why NeuMF Performs Better\n",
        "Architectural Advantages:\n",
        "\n",
        "NeuMF combines matrix factorization and neural networks, capturing both linear and non-linear patterns\n",
        "\n",
        "The GCNN implementation appears to be failing to learn meaningful representations\n",
        "\n",
        "Data Suitability:\n",
        "\n",
        "NeuMF is specifically designed for implicit feedback scenarios\n",
        "\n",
        "The GCNN may be suffering from:\n",
        "\n",
        "Poor message passing between nodes\n",
        "\n",
        "Inadequate feature representation\n",
        "\n",
        "Improper hyperparameter tuning\n",
        "\n",
        "Implementation Factors:\n",
        "\n",
        "The GCNN's poor performance suggests potential bugs in:\n",
        "\n",
        "Edge construction\n",
        "\n",
        "Loss computation\n",
        "\n",
        "Node feature representation\n",
        "\n",
        "NeuMF's more straightforward architecture may be more robust to implementation errors"
      ],
      "metadata": {
        "id": "t2gm0NbmvFRR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYvJq4c4iz2l"
      },
      "source": [
        "# Step 2: Generating Recommendations and Evaluating for a Specific Customer [40 points]\n",
        "\n",
        "1- Mapping Customer IDs to Indices.\n",
        "\n",
        "2- Get Predicted Scores for the Customer.\n",
        "\n",
        "3- Rank Items by Predicted Scores.\n",
        "\n",
        "4- Map Recommended Items to Stock Codes.\n",
        "\n",
        "5- Compare Recommendations with Actual Interactions.\n",
        "\n",
        "6- Calculate Precision, Recall, and F1 Score."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_to_index = {customer: i for i, customer in enumerate(customers)}\n",
        "index_to_customer = {i: customer for i, customer in enumerate(customers)}\n",
        "item_to_index = {item: j for j, item in enumerate(items)}\n",
        "index_to_item = {j: item for j, item in enumerate(items)}\n"
      ],
      "metadata": {
        "id": "Axv8D-hppjnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_id = customers[0]  # Or any ID of interest\n",
        "customer_idx = customer_to_index[customer_id]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    scores = model(data).view(-1)\n",
        "\n",
        "# Get predicted scores for all item nodes (offset by num_customers)\n",
        "item_scores = scores[num_customers:]  # Only item nodes\n"
      ],
      "metadata": {
        "id": "FbOEhPfMpn4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort items by descending predicted scores\n",
        "top_k = 10\n",
        "ranked_items = torch.topk(item_scores, k=top_k).indices.tolist()\n"
      ],
      "metadata": {
        "id": "50U56fjgpntM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_stock_codes = [index_to_item[i] for i in ranked_items]\n",
        "print(f\"Top-{top_k} recommended items for customer {customer_id}:\")\n",
        "print(recommended_stock_codes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3GCU8IZpv0T",
        "outputId": "2da95ca2-d0e5-4f39-a350-a48d0c7d4fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-10 recommended items for customer 17850:\n",
            "[22423, '85123A', 47566, 21212, 22720, 84879, '85099B', 22960, 23298, 22457]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get actual items purchased by the customer\n",
        "actual_purchased_item_indices = np.where(adjacency_matrix[customer_idx] > 0)[0]\n",
        "actual_stock_codes = [index_to_item[i] for i in actual_purchased_item_indices]\n",
        "\n",
        "print(f\"\\nActual purchased items by customer {customer_id}:\")\n",
        "print(actual_stock_codes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5nH8Z6cpydW",
        "outputId": "ea7ea429-8368-47b0-b818-b865e1b22548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Actual purchased items by customer 17850:\n",
            "['84029E', 71053, 21730, '84406B', 22752, '85123A', '84029G', 22633, 22632, 20679, 21068, 21871, 82483, 21071, 82486, 37370, '82494L', 82482, '15056BL', 22411, 22803]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_f1_set(y_true, y_pred):\n",
        "    y_true_set = set(y_true)\n",
        "    y_pred_set = set(y_pred)\n",
        "    tp = len(y_true_set & y_pred_set)\n",
        "\n",
        "    precision = tp / len(y_pred) if y_pred else 0.0\n",
        "    recall = tp / len(y_true) if y_true else 0.0\n",
        "    f1 = (2 * precision * recall) / (precision + recall + 1e-8)\n",
        "    return precision, recall, f1\n",
        "\n",
        "precision, recall, f1 = precision_recall_f1_set(actual_stock_codes, recommended_stock_codes)\n",
        "\n",
        "print(f\"\\nPrecision@{top_k}: {precision:.4f}\")\n",
        "print(f\"Recall@{top_k}: {recall:.4f}\")\n",
        "print(f\"F1 Score@{top_k}: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp3TXRg5p0w8",
        "outputId": "a0f4405c-9594-47c1-c22c-e27a132ba687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Precision@10: 0.1000\n",
            "Recall@10: 0.0476\n",
            "F1 Score@10: 0.0645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_gcnn_neumf(customer_id, gcnn_model, neumf_model, data, adjacency_matrix, customer_to_index, items, top_k=10):\n",
        "    customer_idx = customer_to_index[customer_id]\n",
        "    num_items = len(items)\n",
        "\n",
        "    # ===== GCNN Predictions =====\n",
        "    gcnn_model.eval()\n",
        "    with torch.no_grad():\n",
        "        gcnn_scores = gcnn_model(data).view(-1)\n",
        "        gcnn_item_scores = gcnn_scores[len(customer_to_index):]  # Only item node predictions\n",
        "        gcnn_top_k_items = torch.topk(gcnn_item_scores, k=top_k).indices.tolist()\n",
        "        gcnn_stockcodes = [items[i] for i in gcnn_top_k_items]\n",
        "\n",
        "    # ===== NeuMF Predictions =====\n",
        "    neumf_model.eval()\n",
        "    with torch.no_grad():\n",
        "        item_indices = torch.arange(num_items)\n",
        "        user_tensor = torch.full((num_items,), customer_idx, dtype=torch.long)\n",
        "        neumf_scores = neumf_model(user_tensor, item_indices)\n",
        "        neumf_top_k_items = torch.topk(neumf_scores, k=top_k).indices.tolist()\n",
        "        neumf_stockcodes = [items[i] for i in neumf_top_k_items]\n",
        "\n",
        "    # ===== Actual Interactions =====\n",
        "    actual_indices = np.where(adjacency_matrix[customer_idx] > 0)[0]\n",
        "    actual_stockcodes = [items[i] for i in actual_indices]\n",
        "\n",
        "    # ===== Print Results =====\n",
        "    print(f\"\\n🧾 Recommendations for Customer ID {customer_id}\")\n",
        "    print(f\"GCNN  Top-{top_k} StockCodes:  {gcnn_stockcodes}\")\n",
        "    print(f\"NeuMF Top-{top_k} StockCodes:  {neumf_stockcodes}\")\n",
        "    print(f\"Actual StockCodes (Purchased): {actual_stockcodes}\")\n",
        "\n",
        "    # Optional: Calculate overlap\n",
        "    overlap = set(gcnn_stockcodes) & set(neumf_stockcodes)\n",
        "    print(f\"Overlap between GCNN and NeuMF: {overlap if overlap else 'None'}\")\n",
        "\n",
        "# 🔍 Call the function for customer 17850\n",
        "compare_gcnn_neumf(\n",
        "    customer_id=17850,\n",
        "    gcnn_model=gcnn_model,\n",
        "    neumf_model=neumf_model,\n",
        "    data=data,\n",
        "    adjacency_matrix=adjacency_matrix,\n",
        "    customer_to_index=customer_to_index,\n",
        "    items=items,\n",
        "    top_k=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShBThdJJtIvn",
        "outputId": "8f28d200-f9dc-4bc3-debf-3192040cc050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧾 Recommendations for Customer ID 17850\n",
            "GCNN  Top-10 StockCodes:  ['90214M', 21895, '90214J', '90214V', 21370, '90214S', 21268, 22275, 82615, 84854]\n",
            "NeuMF Top-10 StockCodes:  ['72802C', 79163, 23370, 84949, 22889, 22366, '84032B', 20816, 22038, 46118]\n",
            "Actual StockCodes (Purchased): ['84029E', 71053, 21730, '84406B', 22752, '85123A', '84029G', 22633, 22632, 20679, 21068, 21871, 82483, 21071, 82486, 37370, '82494L', 82482, '15056BL', 22411, 22803]\n",
            "Overlap between GCNN and NeuMF: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison Summary\n",
        "Overlap Between GCNN & NeuMF:\n",
        "None. The two models produced completely different top-10 recommendations.\n",
        "\n",
        "Overlap with Actual Purchases:\n",
        "None of the top-10 recommended items from either GCNN or NeuMF appear in the actual purchases for customer 17850.\n",
        "\n",
        "Inference:\n",
        "\n",
        "Both models have distinct recommendation strategies. GCNN uses the graph structure of user-item interactions, while NeuMF relies on latent factor learning.\n",
        "\n",
        "Neither model captured the customer’s actual preferences well in this instance — likely due to:\n",
        "\n",
        "Sparse data for this customer.\n",
        "\n",
        "Cold start effects.\n",
        "\n",
        "Lack of side features (e.g., timestamps, categories)."
      ],
      "metadata": {
        "id": "gCwL9sZbtkYz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06lNrA-IjsPR"
      },
      "source": [
        "# Step 3: Discussion of Results [20 points]\n",
        "\n",
        "Discuss the performance of the GCNN model compared to the Feedforward NeuMF model. Provide insights on which model performs better and why, based on the evaluation metrics. Consider aspects like Precision@K, Recall@K, and F1 score.\n",
        "\n",
        "Compare the recommended items for Customer 17850 generated by your model with those recommended by Neo4j. Are there similarities between the two sets of recommendations?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}